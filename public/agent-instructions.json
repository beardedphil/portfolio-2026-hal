{
  "index": {
    "basic": [
      "agent-instructions",
      "qa-audit-report",
      "heading-parsing-pitfalls",
      "code-location-citations",
      "code-citation-requirements",
      "state-management-change-documentation",
      "key-decisions-summary"
    ],
    "situational": {},
    "topics": {
      "agent-instructions": {
        "title": "Agent Instructions Entry Point",
        "description": "Entry point for agent instructions - load basic rules from Supabase",
        "agentTypes": [
          "all"
        ]
      },
      "code-location-citations": {
        "title": "Code Location Citations",
        "description": "Require agents to cite concrete code locations that reviewers can verify quickly",
        "agentTypes": [
          "all"
        ]
      },
      "code-citation-requirements": {
        "title": "Code Citation Requirements",
        "description": "Require agents to cite specific file paths and line numbers when referencing code locations",
        "agentTypes": [
          "all"
        ]
      },
      "state-management-change-documentation": {
        "title": "State Management Change Documentation",
        "description": "Require agents to document and justify any changes to application state management in review artifacts",
        "agentTypes": [
          "all"
        ]
      },
      "key-decisions-summary": {
        "title": "Key Decisions Summary Requirement",
        "description": "Require agents to include a \"Key decisions\" summary in completion write-ups so reviewers can understand tradeoffs without re-reading entire worklogs",
        "agentTypes": [
          "all"
        ]
      }
    }
  },
  "instructions": [
    {
      "path": "ac-confirmation-checklist.mdc",
      "name": "ac confirmation checklist",
      "description": "AC Confirmation Checklist - mandatory step before marking tickets complete",
      "alwaysApply": true,
      "content": "# AC Confirmation Checklist\n\n**MANDATORY:** Before marking a ticket complete or moving it forward in the workflow, agents **MUST** perform an explicit Acceptance Criteria (AC) confirmation checklist. This applies to **Implementation**, **QA**, and **PM** agents where relevant.\n\n## When to Perform AC Confirmation\n\n- **Implementation agents:** Before moving ticket to \"Ready for QA\" and sending completion summary\n- **QA agents:** Before moving ticket to \"Human in the Loop\" and sending completion summary\n- **PM agents:** Before marking ticket complete or moving to final status (where applicable)\n\n**CRITICAL:** The AC confirmation checklist must be completed **before** any final summary message or ticket movement. Do not mark a ticket complete or move it forward without completing this checklist.\n\n## AC Confirmation Checklist Requirements\n\n### 1. Enumerate Each Acceptance Criteria\n\nYou **MUST** enumerate every single Acceptance Criteria line item from the ticket. For each AC:\n\n- List the full text of the AC (or a clear reference that uniquely identifies it)\n- State **\"Met\"** or **\"Not met\"** for each AC\n- Provide **evidence** for your determination\n\n### 2. Evidence Requirements\n\nFor each AC marked as **\"Met\"**, provide one or more of the following types of evidence:\n\n- **Links to artifacts:** Reference specific artifacts stored in Supabase (e.g., \"See Plan artifact for ticket 0191, section X\")\n- **File paths:** Reference specific files and line numbers where the requirement is implemented (e.g., \"`.cursor/rules/ac-confirmation-checklist.mdc` lines 15-25\")\n- **Screenshots:** If applicable, reference screenshots stored in artifacts\n- **Reproduction steps:** Clear steps a human can follow to verify the AC is met (e.g., \"Navigate to X, click Y, verify Z appears\")\n\nFor each AC marked as **\"Not met\"**, clearly state:\n- Why it is not met\n- What work remains\n- What the next steps are (see \"Handling Unmet ACs\" below)\n\n### 3. Handling Unmet Acceptance Criteria\n\n**MANDATORY:** If any AC is marked as **\"Not met\"**, you **MUST** clearly state what happens next:\n\n- **Do not mark complete:** The ticket cannot be marked complete or moved to a \"done\" status\n- **Update plan or open follow-up:** If the AC requires additional work, either:\n  - Update the implementation plan to include the missing work, OR\n  - Create/open a bugfix or follow-up ticket to address the unmet AC\n- **Move to appropriate column:** Move the ticket to the appropriate column (e.g., \"To-do\" if work remains, \"Will Not Implement\" if the AC is intentionally not being met)\n\n**CRITICAL:** You **MUST NOT** mark a ticket complete or move it forward if any AC is not met, unless explicitly documented that the AC is intentionally not being met (with justification).\n\n## Human-Verifiable Format\n\nThe AC confirmation checklist must be written so a human can verify it **purely via UI artifacts and the agent's final summary**. This means:\n\n- **Include in final summary:** The AC confirmation checklist must appear in the agent's final completion message/summary\n- **Reference artifacts:** Evidence should reference artifacts that are stored in Supabase and accessible via the HAL app UI\n- **No terminal-only verification:** All evidence must be verifiable through the HAL app UI (artifacts, ticket content, etc.) without requiring terminal access\n\n### Example AC Confirmation Checklist Format\n\n```markdown\n## AC Confirmation Checklist\n\n### AC 1: \"A new, explicit 'AC Confirmation checklist' section exists in the agent process docs/rules\"\n- **Status:** Met\n- **Evidence:** \n  - New rule file created: `.cursor/rules/ac-confirmation-checklist.mdc`\n  - See artifact: \"Plan for ticket 0191\" section \"Implementation Details\"\n  - File path: `.cursor/rules/ac-confirmation-checklist.mdc` lines 1-150\n\n### AC 2: \"The checklist requires the agent to enumerate each Acceptance Criteria line item from the ticket and write 'Met / Not met' with evidence\"\n- **Status:** Met\n- **Evidence:**\n  - See this section (lines 25-45) which requires enumeration and Met/Not met status\n  - See artifact: \"Verification for ticket 0191\" which demonstrates the checklist format\n\n### AC 3: \"The checklist requires the agent to state what happens when any AC is not met\"\n- **Status:** Met\n- **Evidence:**\n  - See \"Handling Unmet Acceptance Criteria\" section (lines 60-75)\n  - This section explicitly requires stating next steps when ACs are not met\n\n### AC 4: \"The workflow is written so a human can verify it purely via the UI artifacts and the agent's final summary\"\n- **Status:** Met\n- **Evidence:**\n  - See \"Human-Verifiable Format\" section (lines 80-95)\n  - This section requires all evidence to be verifiable via HAL app UI\n\n### AC 5: \"Documentation/rules updates are scoped to process changes only (no product feature implementation required)\"\n- **Status:** Met\n- **Evidence:**\n  - Only documentation files were created/modified (`.cursor/rules/ac-confirmation-checklist.mdc`)\n  - No product code changes were made\n  - See artifact: \"Changed Files for ticket 0191\"\n```\n\n## Integration with Existing Workflows\n\n### For Implementation Agents:\n\n1. Complete all implementation work\n2. Store all required artifacts\n3. **Perform AC Confirmation Checklist** (this step)\n4. If all ACs are met: Move ticket to \"Ready for QA\" and send completion summary\n5. If any AC is not met: Do not move ticket; update plan or create follow-up ticket\n\n### For QA Agents:\n\n1. Verify required implementation artifacts are present\n2. Perform code review and verification\n3. **Perform AC Confirmation Checklist** (this step) - verify that implementation met all ACs\n4. If all ACs are met: Store QA report, move ticket to \"Human in the Loop\", merge to main, send completion summary\n5. If any AC is not met: Store QA report with FAIL verdict, move ticket to \"To-do\", send summary\n\n### For PM Agents:\n\n1. Review ticket and artifacts\n2. **Perform AC Confirmation Checklist** (this step) - verify that all ACs are met\n3. If all ACs are met: Mark ticket complete or move to final status\n4. If any AC is not met: Do not mark complete; move to appropriate column\n\n## Storage of AC Confirmation Checklist\n\nThe AC confirmation checklist should be:\n\n- **Included in the agent's final summary message** (mandatory)\n- **Stored in an artifact** (recommended for Implementation and QA agents):\n  - Implementation agents: Include in \"Verification for ticket <ticket-id>\" artifact\n  - QA agents: Include in \"QA report for ticket <ticket-id>\" artifact\n  - PM agents: Include in \"PM Review for ticket <ticket-id>\" artifact (if applicable)\n\nThis ensures the checklist is human-verifiable via the HAL app UI.\n\n## Scope\n\n- **Applies to:** Implementation agents, QA agents, PM agents\n- **Applies when:** Before marking tickets complete or moving them forward in workflow\n- **Mandatory:** Yes - this is a required step, not optional\n",
      "agentTypes": [
        "all",
        "qa-agent",
        "implementation-agent",
        "project-manager"
      ],
      "topicId": "ac-confirmation-checklist",
      "isBasic": false,
      "isSituational": false
    },
    {
      "path": "agent-instructions.mdc",
      "name": "agent instructions",
      "description": "How to access agent instructions via HAL API",
      "alwaysApply": true,
      "content": "# Agent Instructions\n\nAgent instructions are stored in Supabase and accessed via HAL API endpoints. This file is an entry point to the instruction system.\n\n## Accessing Instructions\n\n### For Agents\n\nAgents should access instructions via HAL API endpoints (preferred) or directly from Supabase (fallback).\n\n**HAL API Endpoints:**\n\n- **Get all instructions:** `POST /api/instructions/get`\n  - Body: `{ repoFullName?: string, agentType?: string, includeBasic?: boolean, includeSituational?: boolean }`\n  - Returns: List of instructions filtered by agent type and instruction type\n\n- **Get specific topic:** `POST /api/instructions/get-topic`\n  - Body: `{ topicId: string, repoFullName?: string }`\n  - Returns: Full instruction content for a specific topic (used by `get_instruction_set` tool)\n\n- **Get instruction index:** `POST /api/instructions/get-index`\n  - Body: `{ repoFullName?: string }`\n  - Returns: Instruction index metadata with available topics\n\n**Example (get basic instructions):**\n```javascript\nconst baseUrl = (await readFile('.hal/api-base-url', 'utf8')).trim()\nconst res = await fetch(`${baseUrl}/api/instructions/get`, {\n  method: 'POST',\n  headers: { 'Content-Type': 'application/json' },\n  body: JSON.stringify({\n    agentType: 'project-manager',\n    includeBasic: true,\n    includeSituational: false,\n  }),\n})\nconst result = await res.json()\nif (result.success) {\n  // result.instructions contains the basic instructions\n}\n```\n\n**Example (get specific topic):**\n```javascript\nconst res = await fetch(`${baseUrl}/api/instructions/get-topic`, {\n  method: 'POST',\n  headers: { 'Content-Type': 'application/json' },\n  body: JSON.stringify({\n    topicId: 'auditability-and-traceability',\n  }),\n})\nconst result = await res.json()\nif (result.success) {\n  // result.content contains the full instruction content\n}\n```\n\n### Instruction Structure\n\nInstructions are organized into:\n\n1. **Basic Instructions** - Always loaded for all agents (minimal core instructions)\n2. **Situational Instructions** - Available on-demand via `get_instruction_set` tool\n\n### For Users\n\nUsers can browse and edit instructions in the HAL app:\n- Click \"Agent Instructions\" button in the header\n- Browse the instruction hierarchy (All Agents → Agent → Instruction)\n- Click \"Edit\" to modify instructions (saves directly to Supabase)\n\n### Instruction Storage\n\n- **Storage:** Supabase `agent_instructions` and `agent_instruction_index` tables\n- **Editing:** Via HAL app UI (writes to Supabase)\n- **Access:** Via HAL API endpoints (no direct Supabase access needed)\n\nSee `.cursor/rules/agent-supabase-api-paradigm.mdc` for full API endpoint documentation.\n\n## Moving Tickets After Implementation\n\n**⚠️ CRITICAL MANDATORY STEP - DO NOT SKIP THIS ⚠️**\n\n**MANDATORY:** After completing implementation work, implementation agents **MUST** move the ticket to **Ready for QA** using the HAL API. This is **not optional** - failing to move the ticket to Ready for QA means the implementation workflow is incomplete and the ticket will remain in the wrong column.\n\n**YOU MUST MOVE THE TICKET BEFORE SENDING YOUR COMPLETION SUMMARY. DO NOT SAY \"DONE\" OR \"COMPLETE\" WITHOUT MOVING THE TICKET FIRST.**\n\n**Move ticket to Ready for QA (REQUIRED BEFORE COMPLETION):**\n```javascript\nconst baseUrl = (await readFile('.hal/api-base-url', 'utf8')).trim()\nconst res = await fetch(`${baseUrl}/api/tickets/move`, {\n  method: 'POST',\n  headers: { 'Content-Type': 'application/json' },\n  body: JSON.stringify({\n    ticketId: '0167', // The ticket ID (e.g., '0167' for HAL-0167)\n    columnId: 'col-qa', // Ready for QA column\n  }),\n})\nconst result = await res.json()\nif (result.success) {\n  // Ticket moved successfully to position result.position\n  // NOW you can send your completion summary\n} else {\n  // If move fails, DO NOT send completion summary - fix the issue first\n  throw new Error(`Failed to move ticket: ${result.error}`)\n}\n```\n\n**Ticket ID formats:**\nThe `/api/tickets/move` endpoint accepts multiple ticket ID formats for flexibility:\n- Numeric ID: `'172'` (the actual id field value)\n- With leading zeros: `'0172'` (will be normalized automatically)\n- Display ID: `'HAL-0172'` (will be resolved to the numeric id)\n\nThe API automatically handles these formats by trying multiple lookup strategies, so you can use whichever format is most convenient. The API will find the ticket regardless of format and use the ticket's primary key (pk) for the update to ensure reliability.\n\n**When to move (MANDATORY WORKFLOW):**\n1. ✅ After all code changes are committed and pushed\n2. ✅ After all required artifacts are stored (if applicable)\n3. ✅ **MOVE THE TICKET TO READY FOR QA** (use the API call above)\n4. ✅ **THEN** send your final \"implementation complete\" summary message\n\n**CRITICAL WORKFLOW RULE:** \n- **DO NOT** send a completion summary or \"done\" message without first moving the ticket to Ready for QA\n- **DO NOT** mark the ticket as complete in your message if you haven't moved it\n- The ticket move is **part of the completion workflow**, not an optional step\n- If the move fails, **DO NOT** proceed with completion - fix the issue and retry the move\n\n**Available column IDs:**\n- `col-unassigned` - Unassigned\n- `col-todo` - To-do\n- `col-doing` - Doing (Active Work)\n- `col-qa` - Ready for QA\n- `col-human-in-the-loop` - Human in the Loop\n- `col-process-review` - Process Review\n- `col-done` - Done\n- `col-wont-implement` - Will Not Implement\n\n**Note:** The HAL API endpoint `/api/tickets/move` uses server-side Supabase credentials, so agents don't need to provide credentials in the request body. The API uses the ticket's primary key (pk) for updates to ensure reliable ticket movement regardless of the ticket ID format provided.\n",
      "agentTypes": [
        "all",
        "implementation-agent",
        "project-manager",
        "process-review-agent"
      ],
      "topicId": "agent-instructions",
      "isBasic": true,
      "isSituational": false,
      "topicMetadata": {
        "title": "Agent Instructions Entry Point",
        "description": "Entry point for agent instructions - load basic rules from Supabase",
        "agentTypes": [
          "all"
        ]
      }
    },
    {
      "path": "code-citation-requirements.mdc",
      "name": "code citation requirements",
      "description": "Require agents to cite specific file paths and line numbers when referencing code locations",
      "alwaysApply": true,
      "content": "# Code Citation Requirements\n\nWhen agents reference \"where something is implemented\" or claim where key functionality exists, they **must** cite concrete code locations using file paths and (when feasible) line numbers or symbol names. This enables reviewers to verify claims quickly without searching the codebase.\n\n## Mandatory Citation Format\n\n**Minimum acceptable citation formats:**\n\n1. **File path with line range:** `src/foo.ts:42-61`\n2. **File path with single line:** `src/foo.ts:42`\n3. **File path with symbol name:** `src/foo.ts — function bar()` or `src/foo.ts — class MyComponent`\n4. **File path with line and symbol:** `src/foo.ts:42 — function bar()`\n\n**Examples:**\n- ✅ `src/api/tickets.ts:123-145` — implementation of ticket syncing\n- ✅ `components/KanbanBoard.tsx:42` — column rendering logic\n- ✅ `src/utils/validation.ts — function validateTicket()` — validation rules\n- ✅ `src/hooks/useTickets.ts:78-92 — useEffect hook` — data fetching\n- ❌ \"in the tickets API file\" — too vague\n- ❌ \"tickets.ts\" — missing path context\n- ❌ \"the validation function\" — no file reference\n\n## Required Contexts\n\nThis requirement applies to all of the following contexts:\n\n### 1. Implementation Summaries and Worklogs\n\nWhen implementation agents document what was implemented, they must cite specific locations:\n\n**Example (worklog):**\n```markdown\n## Changes Made\n\n- Added ticket syncing logic in `src/api/tickets.ts:123-145` — `syncTickets()` function\n- Updated column rendering in `components/KanbanBoard.tsx:42-67` — `renderColumns()` method\n- Fixed validation in `src/utils/validation.ts:89-102 — validateTicket()` function\n```\n\n### 2. QA Reports\n\nWhen QA agents review code and report findings, they must cite specific locations:\n\n**Example (QA report code review section):**\n```markdown\n## Code Review\n\n| Requirement | Implementation | Status |\n|------------|----------------|--------|\n| Ticket syncing | `src/api/tickets.ts:123-145 — syncTickets()` | ✅ PASS |\n| Column rendering | `components/KanbanBoard.tsx:42-67` | ✅ PASS |\n| Validation | `src/utils/validation.ts:89-102 — validateTicket()` | ⚠️ FAIL — missing null check |\n```\n\n### 3. PM Guidance\n\nWhen Project Manager agents answer questions like \"Where is X implemented?\" or \"How does Y work?\", they must cite specific locations:\n\n**Example (PM response):**\n```markdown\nTicket syncing is implemented in `src/api/tickets.ts:123-145` in the `syncTickets()` function. The function handles:\n- Fetching tickets from Supabase (`src/api/tickets.ts:130-138`)\n- Updating local state (`src/api/tickets.ts:140-145`)\n```\n\n## Exceptions: When Line Numbers Are Unreliable\n\nWhen line numbers are unreliable or unstable (e.g., generated code, minified bundles, frequently changing files), cite the nearest stable anchor instead:\n\n**Acceptable alternatives:**\n- **Symbol name + file path:** `src/generated/api.ts — export function fetchTickets()`\n- **Exported function/class:** `src/api/index.ts — export { syncTickets }`\n- **Route ID or path:** `src/routes.ts — route id: 'tickets'`\n- **Component name:** `components/TicketCard.tsx — <TicketCard /> component`\n- **Configuration key:** `config/app.config.ts — tickets.syncInterval`\n\n**Examples:**\n- ✅ `dist/bundle.js — function syncTickets()` (minified bundle)\n- ✅ `src/generated/types.ts — interface Ticket` (generated file)\n- ✅ `src/routes.ts — route: '/tickets'` (routing config)\n- ❌ `dist/bundle.js:1234` (line number in minified code is unreliable)\n\n**When in doubt:** Prefer symbol names, exported identifiers, or stable configuration keys over line numbers in generated or frequently-changing files.\n\n## Enforcement\n\n- **Implementation agents:** Must include citations in worklogs, plans, and implementation summaries.\n- **QA agents:** Must include citations in code review sections of QA reports (see `.cursor/rules/qa-audit-report.mdc`).\n- **PM agents:** Must include citations when answering \"where is X implemented?\" questions.\n\n**Reviewers should verify:** All code location claims can be verified by navigating to the cited file path and (when provided) line number or symbol name.\n",
      "agentTypes": [
        "all",
        "qa-agent",
        "implementation-agent",
        "project-manager"
      ],
      "topicId": "code-citation-requirements",
      "isBasic": true,
      "isSituational": false,
      "topicMetadata": {
        "title": "Code Citation Requirements",
        "description": "Require agents to cite specific file paths and line numbers when referencing code locations",
        "agentTypes": [
          "all"
        ]
      }
    },
    {
      "path": "code-location-citations.mdc",
      "name": "code location citations",
      "description": "Require agents to cite specific file paths and line numbers/symbols when referencing where functionality is implemented",
      "alwaysApply": true,
      "content": "# Code Location Citations\n\nWhen an agent references \"where something is implemented\" or claims where key functionality exists, they **must** cite concrete code locations that reviewers can verify quickly.\n\n## Required Citation Format\n\n**Minimum acceptable citation formats:**\n\n- **File path with line range:** `src/foo.ts:42-61`\n- **File path with function/class name:** `src/foo.ts — function bar()`\n- **File path with symbol:** `src/foo.ts — class MyComponent`\n- **File path with route/component ID:** `src/routes.ts — route id: \"dashboard\"`\n\n**Examples:**\n- ✅ `src/components/Button.tsx:15-23` (line range)\n- ✅ `src/utils/api.ts — function fetchUser()` (symbol name)\n- ✅ `src/routes.ts:42 — route id: \"settings\"` (route identifier)\n- ✅ `src/App.tsx — component App` (component name)\n- ❌ `src/components/Button.tsx` (missing line/symbol)\n- ❌ `the Button component` (no file path)\n\n## When Citations Are Required\n\nCitations are **mandatory** in these contexts:\n\n1. **Implementation summaries/worklogs** — When describing what was implemented or where changes were made\n2. **QA reports** — When reviewing code and referencing where functionality exists\n3. **PM guidance** — When answering \"where is X implemented?\" or similar questions\n\n## Exceptions: Unreliable Line Numbers\n\nIf line numbers are unreliable or unstable (e.g., generated code, minified bundles, auto-generated files), cite the **nearest stable anchor** instead:\n\n- **Symbol name** (exported function, class, constant)\n- **Route ID** or **component name**\n- **Export identifier**\n- **File path** (always required, even when line numbers aren't)\n\n**Examples of stable anchors:**\n- `src/generated/api.ts — export function createUser()` (generated file, use symbol)\n- `dist/bundle.js — function handleClick()` (minified, use symbol)\n- `src/routes.ts — route id: \"dashboard\"` (route identifier)\n\n**Always include the file path** even when using stable anchors instead of line numbers.\n\n## Scope\n\n- Applies to **all agents** (implementation, QA, PM) when referencing code locations\n- Citations must be **human-verifiable** — a reviewer should be able to open the file and find the referenced location\n- When in doubt, provide **more specific citations** (line numbers + symbol names) rather than less\n",
      "agentTypes": [
        "all"
      ],
      "topicId": "code-location-citations",
      "isBasic": true,
      "isSituational": false,
      "topicMetadata": {
        "title": "Code Location Citations",
        "description": "Require agents to cite concrete code locations that reviewers can verify quickly",
        "agentTypes": [
          "all"
        ]
      }
    },
    {
      "path": "heading-parsing-pitfalls.mdc",
      "name": "heading parsing pitfalls",
      "description": "Guide for agents to produce headings that HAL can parse and render correctly",
      "alwaysApply": true,
      "content": "# Heading parsing pitfalls (and how to avoid them)\n\nWhen creating tickets or writing documentation, agents must produce headings that HAL can parse and render correctly. This guide covers common pitfalls and how to avoid them.\n\n## Pitfall 1: Inconsistent heading levels\n\n**Problem:** Using `#` (H1) or `###` (H3) when `##` (H2) is required, or skipping heading levels (e.g., going from `##` to `####`).\n\n**Why this fails:** HAL's parsing logic expects specific heading levels. Required ticket sections must use `##` (H2) to be recognized correctly.\n\n**❌ Bad examples:**\n```markdown\n# Goal (one sentence)\n\nAdd a feature.\n\n### Acceptance criteria\n\n- [ ] Item 1\n```\n\n```markdown\n## Goal (one sentence)\n\nAdd a feature.\n\n#### Acceptance criteria\n\n- [ ] Item 1\n```\n\n**✅ Good example:**\n```markdown\n## Goal (one sentence)\n\nAdd a feature.\n\n## Acceptance criteria (UI-only)\n\n- [ ] Item 1\n```\n\n**Fix:** Always use `##` (H2) for required ticket sections. Maintain consistent heading hierarchy throughout the document.\n\n## Pitfall 2: Ambiguous \"pseudo-headings\" instead of real markdown headings\n\n**Problem:** Using bold text (`**Section Name:**`) or text with colons (`Section Name:`) when a real markdown heading is intended.\n\n**Why this fails:** HAL's parsing logic looks for markdown heading syntax (`## Section Name`), not bold text or colons. Pseudo-headings won't be recognized as section boundaries.\n\n**❌ Bad examples:**\n```markdown\n**Goal (one sentence):**\n\nAdd a feature.\n\n**Acceptance criteria (UI-only):**\n\n- [ ] Item 1\n```\n\n```markdown\nGoal (one sentence):\n\nAdd a feature.\n\nAcceptance criteria (UI-only):\n\n- [ ] Item 1\n```\n\n**✅ Good example:**\n```markdown\n## Goal (one sentence)\n\nAdd a feature.\n\n## Acceptance criteria (UI-only)\n\n- [ ] Item 1\n```\n\n**Fix:** Use proper markdown heading syntax (`## Section Name`) instead of bold text or plain text with colons.\n\n## Pitfall 3: Required ticket headings don't match canonical text exactly\n\n**Problem:** Using variations like \"Goal\" instead of \"Goal (one sentence)\", or \"Acceptance criteria\" instead of \"Acceptance criteria (UI-only)\".\n\n**Why this fails:** HAL's parsing logic uses case-sensitive, exact text matching. Headings must match the canonical format exactly to be recognized.\n\n**❌ Bad examples:**\n```markdown\n## Goal\n\nAdd a feature.\n\n## Human-verifiable deliverable\n\nUser sees a button.\n\n## Acceptance criteria\n\n- [ ] Item 1\n```\n\n```markdown\n## Goal (one sentence)\n\nAdd a feature.\n\n## Human-verifiable deliverable (UI only)\n\nUser sees a button.\n\n## Acceptance Criteria (UI-only)\n\n- [ ] Item 1\n```\n\n**✅ Good example:**\n```markdown\n## Goal (one sentence)\n\nAdd a feature.\n\n## Human-verifiable deliverable (UI-only)\n\nUser sees a button.\n\n## Acceptance criteria (UI-only)\n\n- [ ] Item 1\n```\n\n**Fix:** Use the exact canonical text for required ticket sections:\n- `## Goal (one sentence)`\n- `## Human-verifiable deliverable (UI-only)`\n- `## Acceptance criteria (UI-only)`\n- `## Constraints`\n- `## Non-goals`\n\n## Pitfall 4: Duplicating the same top-level heading multiple times\n\n**Problem:** Including multiple `# Ticket` blocks or repeating the same top-level section heading.\n\n**Why this fails:** HAL's parsing logic expects a single, well-structured document. Duplicate headings can cause parsing confusion and make sections ambiguous.\n\n**❌ Bad example:**\n```markdown\n# Ticket\n\n## Goal (one sentence)\n\nAdd a feature.\n\n# Ticket\n\n## Goal (one sentence)\n\nAdd another feature.\n```\n\n**✅ Good example:**\n```markdown\n## Goal (one sentence)\n\nAdd a feature.\n\n## Human-verifiable deliverable (UI-only)\n\nUser sees a button.\n\n## Acceptance criteria (UI-only)\n\n- [ ] Item 1\n- [ ] Item 2\n```\n\n**Fix:** Use each heading only once. If you need to group related content, use subheadings (`###`) or organize content within a single section.\n\n## Pitfall 5: Using plain bullets instead of checkboxes in Acceptance criteria\n\n**Problem:** Using `- Item` or `* Item` instead of `- [ ] Item` for Acceptance criteria items.\n\n**Why this fails:** HAL's Ready-to-start checklist requires Acceptance criteria to use checkbox format (`- [ ]`) so items can be tracked and verified. Plain bullets won't pass validation.\n\n**❌ Bad examples:**\n```markdown\n## Acceptance criteria (UI-only)\n\n- User sees a button\n- Button is clickable\n- Clicking shows a message\n```\n\n```markdown\n## Acceptance criteria (UI-only)\n\n* User sees a button\n* Button is clickable\n* Clicking shows a message\n```\n\n**✅ Good example:**\n```markdown\n## Acceptance criteria (UI-only)\n\n- [ ] User sees a button labeled \"Save\" in the header\n- [ ] Button is clickable and responds to clicks\n- [ ] Clicking the button shows a success message in the UI\n```\n\n**Fix:** Always use checkbox format (`- [ ]`) for Acceptance criteria items. Each item should be UI-verifiable (a human can confirm by looking at the UI or running a manual test).\n\n## Copy/paste examples\n\n### Good: Minimal ticket skeleton that passes Definition of Ready\n\n```markdown\n## Goal (one sentence)\n\nAdd a dark mode toggle button to the settings page that persists the user's preference.\n\n## Human-verifiable deliverable (UI-only)\n\nA non-technical user opens the app, navigates to Settings, sees a \"Dark mode\" toggle switch, clicks it, and observes the entire app UI changes from light to dark theme. The preference persists after page refresh.\n\n## Acceptance criteria (UI-only)\n\n- [ ] Settings page displays a \"Dark mode\" toggle switch that is clearly visible and clickable\n- [ ] Clicking the toggle immediately changes the app theme from light to dark (or vice versa) with a smooth transition\n- [ ] The selected theme preference persists after page refresh (the toggle state matches the current theme on reload)\n\n## Constraints\n\n- Keep this task as small as possible while still producing a **human-verifiable** UI change.\n- Verification must require **no external tools** (no terminal, no devtools, no console).\n\n## Non-goals\n\n- Theme customization beyond light/dark (no color pickers or advanced theming)\n- Per-component theme overrides (global theme only)\n```\n\n**Why this is good:**\n- All headings use `##` (H2) consistently\n- Headings match canonical text exactly\n- Acceptance criteria use checkbox format (`- [ ]`)\n- No placeholders or pseudo-headings\n- All sections are present and properly formatted\n\n### Bad: Common failure mode and corrected version\n\n**❌ Bad example (multiple pitfalls):**\n```markdown\n# Ticket\n\n**Goal:** Add dark mode toggle\n\n### Human-verifiable deliverable\n\nUser sees toggle in settings.\n\n## Acceptance criteria\n\n- User sees toggle\n- Toggle works\n- Preference saves\n\n## Constraints\n\n- Use existing theme system\n\n## Non-goals\n\n- Advanced theming\n```\n\n**Problems:**\n1. Uses `# Ticket` (H1) instead of starting with `## Goal`\n2. Uses bold pseudo-heading `**Goal:**` instead of `## Goal (one sentence)`\n3. Uses `###` (H3) for \"Human-verifiable deliverable\" instead of `##`\n4. Missing \"(one sentence)\" and \"(UI-only)\" suffixes in headings\n5. Uses plain bullets (`-`) instead of checkboxes (`- [ ]`) in Acceptance criteria\n6. Acceptance criteria items are not UI-verifiable (too vague)\n\n**✅ Corrected version:**\n```markdown\n## Goal (one sentence)\n\nAdd a dark mode toggle button to the settings page that persists the user's preference.\n\n## Human-verifiable deliverable (UI-only)\n\nA non-technical user opens the app, navigates to Settings, sees a \"Dark mode\" toggle switch, clicks it, and observes the entire app UI changes from light to dark theme. The preference persists after page refresh.\n\n## Acceptance criteria (UI-only)\n\n- [ ] Settings page displays a \"Dark mode\" toggle switch that is clearly visible and clickable\n- [ ] Clicking the toggle immediately changes the app theme from light to dark (or vice versa) with a smooth transition\n- [ ] The selected theme preference persists after page refresh (the toggle state matches the current theme on reload)\n\n## Constraints\n\n- Use existing theme system (no new CSS framework)\n- Theme preference must be stored in localStorage\n\n## Non-goals\n\n- Theme customization beyond light/dark (no color pickers or advanced theming)\n- Per-component theme overrides (global theme only)\n```\n\n**Why this is correct:**\n- All headings use `##` (H2) consistently\n- Headings match canonical text exactly: \"Goal (one sentence)\", \"Human-verifiable deliverable (UI-only)\", \"Acceptance criteria (UI-only)\"\n- Acceptance criteria use checkbox format (`- [ ]`)\n- All items are UI-verifiable with specific, testable descriptions\n- No pseudo-headings or placeholders\n\n## Summary\n\nTo produce headings that HAL can parse correctly:\n\n1. **Use `##` (H2) consistently** for required ticket sections\n2. **Use proper markdown heading syntax** (`## Section Name`), not bold text or colons\n3. **Match canonical text exactly** (case-sensitive): \"Goal (one sentence)\", \"Human-verifiable deliverable (UI-only)\", \"Acceptance criteria (UI-only)\"\n4. **Avoid duplicate top-level headings** — use each heading only once\n5. **Use checkbox format** (`- [ ]`) for Acceptance criteria items, not plain bullets\n\nFollowing these guidelines ensures your tickets will pass HAL's Definition of Ready validation and be correctly parsed and rendered in the UI.\n",
      "agentTypes": [
        "all"
      ],
      "topicId": "heading-parsing-pitfalls",
      "isBasic": true,
      "isSituational": false
    },
    {
      "path": "key-decisions-summary.mdc",
      "name": "key decisions summary",
      "description": "Require agents to include a \"Key decisions\" summary in completion write-ups so reviewers can understand tradeoffs without re-reading entire worklogs",
      "alwaysApply": true,
      "content": "# Key Decisions Summary Requirement\n\n**MANDATORY:** All agent completion write-ups must include a short, explicit **\"Key decisions\"** summary (2–6 bullets) so reviewers can quickly understand tradeoffs and design choices without re-reading the entire worklog or diff.\n\n## When This Requirement Applies\n\nThis requirement applies to **all agents** when completing work:\n\n- **Implementation agents** — Must include \"Key decisions\" in both the **PM Review artifact** and the **final chat completion summary**\n- **QA agents** — Must verify that the \"Key decisions\" section exists and is complete during review\n- **Project Manager agents** — Must check for \"Key decisions\" section when reviewing implementation artifacts\n\n## Required Content: Key Decisions Section\n\n**MANDATORY:** Implementation agents **must** include a \"Key decisions\" section in:\n\n1. **PM Review artifact** (stored in Supabase with `artifactType: \"pm-review\"`)\n2. **Final chat completion summary** (the \"done\" message sent to the user)\n\n### Format\n\nThe \"Key decisions\" section should be a bulleted list (2–6 bullets) that explains:\n\n- **Why approach A was chosen over approach B** (e.g., \"Used Supabase API endpoint instead of direct database access for better error handling and validation\")\n- **Any tradeoffs or risks** (e.g., \"Chose synchronous validation over async to simplify error handling, but this may block UI for large datasets\")\n- **Design choices that affect maintainability** (e.g., \"Stored instructions in Supabase rather than file system to enable runtime updates without deployments\")\n- **Performance or scalability considerations** (e.g., \"Implemented client-side caching to reduce API calls, with 5-minute TTL to balance freshness and performance\")\n- **Integration decisions** (e.g., \"Updated existing instruction update endpoint rather than creating new one to maintain API consistency\")\n\n### Example: Good Key Decisions Section\n\n```markdown\n## Key Decisions\n\n- **Stored instructions in Supabase instead of file system** — Enables runtime updates via HAL UI without requiring deployments or code changes. Tradeoff: Requires Supabase connection, but this is already a dependency for the project.\n\n- **Updated existing `/api/instructions/update` endpoint** — Rather than creating a new endpoint, extended the existing one to maintain API consistency. This keeps the instruction update workflow unified.\n\n- **Added \"Key decisions\" requirement to all agent types** — Not just implementation agents, but also QA and PM agents need to check for this section. This ensures comprehensive review coverage.\n\n- **Included example in instruction file** — Provides concrete guidance on what constitutes a good \"Key decisions\" bullet, helping agents understand the expected level of detail and tradeoff explanation.\n\n- **Required in both PM Review artifact and chat summary** — Ensures visibility in both the structured artifact (for audit trail) and the conversational summary (for immediate review).\n```\n\n### Example: Poor Key Decisions Section (Too Vague)\n\n```markdown\n## Key Decisions\n\n- Used Supabase for storage\n- Updated the API\n- Added requirements\n```\n\n**Why this is poor:** Doesn't explain tradeoffs, alternatives considered, or reasoning. Reviewers can't understand the \"why\" without reading the entire worklog.\n\n## Implementation Agent Requirements\n\n**MANDATORY:** When completing a ticket, implementation agents **must**:\n\n1. **Include \"Key decisions\" in PM Review artifact:**\n   - Store the PM Review artifact via HAL API: `POST /api/artifacts/insert-implementation`\n   - Artifact type: `pm-review`\n   - Title format: `PM Review for ticket <ticket-id>`\n   - The artifact body must include a \"Key decisions\" section with 2–6 bullets\n\n2. **Include \"Key decisions\" in final chat completion summary:**\n   - When sending the completion message (the \"done\" summary), include a \"Key decisions\" section\n   - This can be a brief summary (2–4 bullets) that highlights the most important decisions\n   - The full detailed version should be in the PM Review artifact\n\n### PM Review Artifact Template\n\n```markdown\n# PM Review for ticket <ticket-id>\n\n[Other PM Review content...]\n\n## Key Decisions\n\n- [Bullet 1: Why approach A over B, tradeoffs, risks]\n- [Bullet 2: Design choice affecting maintainability]\n- [Bullet 3: Performance/scalability consideration]\n- [Bullet 4: Integration decision]\n- [Bullet 5-6: Additional important decisions]\n\n[Other PM Review content...]\n```\n\n### Final Chat Summary Template\n\n```markdown\n## Summary\n\n[Brief summary of what was implemented...]\n\n## Key Decisions\n\n- [Most important decision 1]\n- [Most important decision 2]\n- [Most important decision 3]\n\nTicket <ticket-id> implementation completed and moved to QA.\n```\n\n## QA Agent Requirements\n\n**MANDATORY:** When QA agents review a ticket, they **must**:\n\n1. **Verify \"Key decisions\" section exists** — Check both:\n   - PM Review artifact (via HAL API: `POST /api/artifacts/get`)\n   - Final chat completion summary (if available in conversation history)\n\n2. **Verify \"Key decisions\" content quality** — The section should:\n   - Contain 2–6 bullets (not too few, not too many)\n   - Explain tradeoffs or alternatives considered\n   - Provide reasoning, not just descriptions\n   - Be specific enough that reviewers understand the \"why\" without reading the entire worklog\n\n3. **Include \"Key decisions\" review in QA report** — QA reports should include a section confirming:\n   - \"Key decisions\" section exists in PM Review artifact: [Yes / No]\n   - \"Key decisions\" section exists in completion summary: [Yes / No / N/A]\n   - Content quality: [Pass / Fail / Needs improvement]\n   - If missing or incomplete, QA **MUST FAIL** the ticket\n\n### QA Report Template Addition\n\nQA reports should include:\n\n```markdown\n## Key Decisions Review\n\n**Key decisions section in PM Review artifact:** [Yes / No]\n\n**Key decisions section in completion summary:** [Yes / No / N/A]\n\n**Content quality:**\n- [ ] Contains 2–6 bullets: [Yes / No]\n- [ ] Explains tradeoffs or alternatives: [Yes / No]\n- [ ] Provides reasoning (not just descriptions): [Yes / No]\n- [ ] Specific enough to understand \"why\" without reading full worklog: [Yes / No]\n\n**Overall assessment:** [Pass / Fail / Needs improvement]\n\n**If missing or incomplete:** QA **MUST FAIL** the ticket and request the implementation agent to add the \"Key decisions\" section.\n```\n\n## Project Manager Agent Requirements\n\n**MANDATORY:** When Project Manager agents review implementation artifacts, they **must**:\n\n1. **Check for \"Key decisions\" section** — Verify it exists in the PM Review artifact\n\n2. **Verify completeness** — Ensure the section:\n   - Contains 2–6 bullets\n   - Explains tradeoffs and reasoning\n   - Helps reviewers understand design choices quickly\n\n3. **Flag missing sections** — If \"Key decisions\" is missing or incomplete, PM agents should:\n   - Note this in their review\n   - Request the implementation agent to add it\n   - Consider this a blocker for ticket completion\n\n## Integration with Existing Workflows\n\n### PM Review Artifact\n\nThe \"Key decisions\" section must be included in the **PM Review artifact** stored in Supabase:\n- **Artifact type:** `pm-review`\n- **Title format:** `PM Review for ticket <ticket-id>`\n- **Storage:** Via HAL API endpoint `/api/artifacts/insert-implementation` with `artifactType: \"pm-review\"`\n\n### Final Chat Completion Summary\n\nThe \"Key decisions\" section must also be included in the **final chat completion summary** (the \"done\" message):\n- This is the message sent when the implementation agent completes work\n- Can be a brief version (2–4 bullets) highlighting the most important decisions\n- The full detailed version should be in the PM Review artifact\n\n### QA Audit Report\n\nQA agents must verify \"Key decisions\" documentation as part of their standard QA workflow.\n\n## Scope\n\n- Applies to **all agents** (implementation, QA, PM) when completing or reviewing work\n- The \"Key decisions\" section must be **human-verifiable** — a reviewer can open the PM Review artifact and immediately see the key decisions and tradeoffs\n- When in doubt, **include more detail** — it's better to over-explain tradeoffs than to leave reviewers guessing why certain approaches were chosen\n",
      "agentTypes": [
        "all",
        "qa-agent",
        "implementation-agent",
        "project-manager"
      ],
      "topicId": "key-decisions-summary",
      "isBasic": true,
      "isSituational": false,
      "topicMetadata": {
        "title": "Key Decisions Summary Requirement",
        "description": "Require agents to include a \"Key decisions\" summary in completion write-ups so reviewers can understand tradeoffs without re-reading entire worklogs",
        "agentTypes": [
          "all"
        ]
      }
    },
    {
      "path": "qa-audit-report.mdc",
      "name": "qa audit report",
      "description": "QA agents must store QA reports in Supabase via HAL API",
      "alwaysApply": true,
      "content": "# QA Audit Report (QA Agents)\n\nWhen you **QA a ticket** (e.g. user asks to \"QA\", \"verify\", or \"check\" a ticket that is allegedly complete), you **must** store a QA report in Supabase via HAL's API endpoints.\n\n## Cloud QA workflow context\n\nIn cloud environments, QA agents may not have access to feature branches (only `main`). When this is the case, the implementation agent merges the feature branch to `main` before QA begins. QA must then verify from `main` rather than attempting to check out a feature branch. This workflow is indicated when the ticket states \"merged to `main` for QA access\" or similar language.\n\n## Which branch to use (decision rule)\n\n- **If the ticket or prompt states that the implementation was \"merged to main for QA access\"** (or that code is on `main` for QA): \n  - You **must** verify from the **`main`** branch. \n  - Do **not** attempt to locate, check out, or use the feature branch.\n  - **Step 1:** Pull the latest `main` branch: `git checkout main && git pull origin main`\n  - **Step 2:** Perform QA on `main` (code review and verification).\n  - **Step 3:** Record in the QA report that verification was performed against `main` (e.g. \"Verified on `main`; implementation was merged to main for QA access.\").\n  - **Step 4:** Store the QA report in Supabase via HAL API (see \"Storing QA report\" below).\n  - **Step 5:** Move ticket to Human in the Loop via HAL API, then provide summary.\n- **Otherwise:** use the feature branch named in the ticket's QA → Branch field (or the branch you were launched on). Perform QA on that branch, then follow the full workflow (merge to main, delete branch, etc.).\n\n**Important:** When QA cannot access feature branches (cloud QA workflow), the implementation agent merges the feature branch to `main` before QA. In this case, QA must verify from `main` and record this in the QA report stored in Supabase.\n\n## Required implementation artifacts (must be present before QA)\n\n**MANDATORY:** Before performing any QA work, you **must** verify that all required implementation artifacts are present in Supabase. If any are missing, QA **must fail immediately** without attempting code review or verification.\n\n**Required implementation artifacts:**\n1. **Plan artifact** (`artifactType: \"plan\"`, title: `Plan for ticket <ticket-id>`)\n2. **Worklog artifact** (`artifactType: \"worklog\"`, title: `Worklog for ticket <ticket-id>`)\n3. **Changed Files artifact** (`artifactType: \"changed-files\"`, title: `Changed Files for ticket <ticket-id>`)\n   - **MANDATORY:** This artifact is REQUIRED on every ticket and must NEVER be omitted or left blank.\n   - **Content requirements:** The Changed Files artifact must be NON-EMPTY and contain substantive content:\n     - **When files changed:** Must list all file paths that were created/modified/deleted, with a brief one-line description of what changed in each file.\n     - **When no files changed:** Must explicitly state \"No files changed.\" followed by a brief explanation (e.g., \"Docs-only ticket handled via Supabase updates\", \"Investigation only\", \"Repro failed; no code changes made\").\n   - **Process failure:** If the Changed Files artifact is missing, blank, or contains only a title with no substantive content, this is a PROCESS FAILURE and QA MUST FAIL immediately.\n4. **Decisions artifact** (`artifactType: \"decisions\"`, title: `Decisions for ticket <ticket-id>`)\n5. **Verification artifact** (`artifactType: \"verification\"`, title: `Verification for ticket <ticket-id>`)\n6. **PM Review artifact** (`artifactType: \"pm-review\"`, title: `PM Review for ticket <ticket-id>`)\n7. **Git diff artifact** (`artifactType: \"git-diff\"`, title: `Git diff for ticket <ticket-id>`)\n8. **Instructions Used artifact** (`artifactType: \"instructions-used\"`, title: `Instructions Used for ticket <ticket-id>`)\n\n**How to check for artifacts:**\n1. **First step (MANDATORY):** Call HAL API endpoint `/api/artifacts/get` with `{ ticketId: \"<ticket-id>\" }` to fetch all artifacts for the ticket.\n   - If `.hal/api-base-url` exists, read it and call: `POST ${baseUrl}/api/artifacts/get`\n   - If API call fails (404, 500, network error, etc.), **QA MUST FAIL** — you cannot verify artifacts exist, so assume they are missing.\n   - **DO NOT proceed with code review if artifact verification fails.**\n2. Filter the returned artifacts to find implementation artifacts (where `agent_type === \"implementation\"`).\n3. Check that all 8 required artifact types are present by matching artifact titles:\n   - `Plan for ticket <ticket-id>`\n   - `Worklog for ticket <ticket-id>`\n   - `Changed Files for ticket <ticket-id>`\n   - `Decisions for ticket <ticket-id>`\n   - `Verification for ticket <ticket-id>`\n   - `PM Review for ticket <ticket-id>`\n   - `Git diff for ticket <ticket-id>`\n   - `Instructions Used for ticket <ticket-id>`\n4. **CRITICAL: Validate Changed Files artifact content:**\n   - The Changed Files artifact must have NON-EMPTY `body_md` content (not just a title).\n   - If the Changed Files artifact exists but has empty or blank `body_md`, this is a PROCESS FAILURE and QA MUST FAIL immediately.\n   - The content must either:\n     - List file paths with descriptions (when files changed), OR\n     - Explicitly state \"No files changed.\" with a brief explanation (when no files changed).\n   - If Changed Files artifact is missing, blank, or contains only whitespace/placeholders, treat it as missing and fail QA.\n\n**Auto-fail when artifacts are missing or unverifiable:**\n- **If artifact API call fails (404, 500, network error, timeout):** QA **must fail immediately**. You cannot verify artifacts exist, so treat as missing.\n- **If any required artifact is missing:** QA **must fail immediately**.\n- **If Changed Files artifact is blank or empty:** QA **must fail immediately**. This is a PROCESS FAILURE. The Changed Files artifact must contain substantive content (either a list of changed files or an explicit \"No files changed.\" statement with explanation).\n- **Do NOT** attempt code review, verification, or any other QA work when artifacts cannot be verified or are missing.\n- **Do NOT** attempt to \"guess\" or recreate missing artifacts.\n- **Do NOT** proceed with code review and note \"artifacts couldn't be verified\" — this is a FAIL condition.\n- **Record a QA Fail outcome** by storing a QA report that clearly states the failure reason.\n- **The QA report must enumerate the specific missing artifacts** (or state \"Artifact verification failed: API returned [error]\" if API call failed). If Changed Files is blank/empty, explicitly state \"Changed Files artifact is blank or empty (process failure)\".\n- **Store the QA report in Supabase** using `insert_qa_artifact` tool (via HAL API or queue file).\n- **Move ticket to To-do** (`col-todo`) via HAL API.\n- **The final message must include:** `QA RESULT: FAIL — <ticket-id>` (see \"Completion message format requirement\" below).\n\n**Example QA report when artifacts are missing:**\n```markdown\n# QA Report for ticket 0076\n\n## Ticket & Deliverable\n[Brief summary from ticket]\n\n## Missing Required Implementation Artifacts\n\n**QA FAILED:** Required implementation artifacts are missing. QA cannot proceed without complete implementation artifacts.\n\n**Missing artifacts:**\n- Plan artifact (`Plan for ticket 0076`)\n- PM Review artifact (`PM Review for ticket 0076`)\n\n**Present artifacts:**\n- Worklog artifact\n- Changed Files artifact (present but blank/empty - process failure)\n- Decisions artifact\n- Verification artifact\n\n## Verdict\n\n**FAIL** — Implementation artifacts incomplete. Implementation agent must store all required artifacts before QA can proceed.\n\nQA RESULT: FAIL — 0076\n```\n\n**If all required artifacts are present:** Proceed with normal QA workflow (code review, verification, etc.).\n\n**CRITICAL:** Artifact verification is the **first and mandatory step** of QA. Do not skip it, do not defer it, do not proceed with code review if verification fails. If you cannot verify artifacts exist, the ticket fails QA.\n\n**Changed Files artifact validation:**\n- **MANDATORY:** The Changed Files artifact must be present and NON-EMPTY on every ticket.\n- **When files changed:** The artifact must contain a list of file paths and a brief one-line description of what changed in each file.\n- **When no files changed:** The artifact must explicitly state \"No files changed.\" followed by a short reason (e.g., \"Docs-only ticket handled via Supabase updates\", \"Investigation only\", \"Repro failed; no code changes made\").\n- **Process failure:** If the Changed Files artifact is blank, contains only headings, consists of placeholder text, or omits the explicit \"No files changed.\" statement when applicable, this is a PROCESS FAILURE and QA **MUST FAIL** immediately.\n- **QA must verify:** Check that the Changed Files artifact content is substantive and follows the requirements above. If it does not, fail QA and move the ticket back to To-do.\n\n## Required artifact (QA report)\n\n- **Storage:** Supabase `agent_artifacts` table (via HAL API endpoint `/api/artifacts/insert-qa`)\n- **When:** After performing QA (code review and, if possible, UI verification) for a ticket, OR when auto-failing due to missing implementation artifacts.\n- **Agent type:** `qa`\n- **Title format:** `QA report for ticket <ticket-id>`\n\n## QA report structure\n\n1. **Ticket & deliverable** — One-line goal, deliverable, and acceptance criteria from the ticket.\n2. **Missing Required Implementation Artifacts** (if applicable) — List of missing artifacts. If artifacts are missing, this section must be present and QA must fail.\n3. **Audit artifacts** — Confirm all required implementation artifacts are present in Supabase (plan, worklog, changed-files, decisions, verification, pm-review). Only include this section if all artifacts are present.\n   - **Changed Files artifact verification (MANDATORY):** Verify that the Changed Files artifact is non-empty and follows requirements:\n     - If files changed: Must list file paths with brief per-file descriptions (one line each)\n     - If no files changed: Must explicitly state \"No files changed.\" followed by a brief reason (e.g., \"Docs-only ticket handled via Supabase updates\", \"Investigation only\", \"Repro failed; no code changes made\")\n     - If Changed Files artifact is blank, empty, or omitted: QA **MUST FAIL** — this is a process failure\n4. **Code review** — PASS/FAIL with brief evidence (e.g. table of requirement vs implementation; file and line refs if helpful). Only include if artifacts are present.\n5. **Build verification** — **MANDATORY:** Run `npm run build:hal` (or `tsc -b`) and verify it completes with zero TypeScript errors. If TypeScript errors exist, QA **MUST FAIL** immediately. Document the build result (PASS/FAIL) and any TypeScript errors found. Only include if artifacts are present.\n6. **UI verification** — What was run: automated and/or manual steps. If automated UI was not run (e.g. native dialogs, login, or pickers), state that and list the manual steps the user should run. Only include if artifacts are present.\n7. **AC Confirmation Checklist** — **MANDATORY:** Enumerate every Acceptance Criteria from the ticket. For each AC, state \"Met\" or \"Not met\" with evidence (artifact links, file paths, screenshots, or reproduction steps). If any AC is not met, QA **MUST FAIL**. See `.cursor/rules/ac-confirmation-checklist.mdc` for full requirements. Only include if artifacts are present.\n8. **Verdict** — Implementation complete? OK to merge? Any blocking manual verification? Must clearly state PASS or FAIL.\n\n## Storing QA report\n\n**CRITICAL: You must make actual HTTP API calls, not just include JSON blocks in your message.**\n\n**How to store the QA report:**\n\n1. Read the API base URL from `.hal/api-base-url` (if it exists)\n2. Make an HTTP POST request to `${baseUrl}/api/artifacts/insert-qa` with:\n   - Headers: `Content-Type: application/json`\n   - Body: `{ \"ticketId\": \"0076\", \"title\": \"QA report for ticket 0076\", \"body_md\": \"<full markdown content>\" }`\n3. Use `curl` or `run_terminal_cmd` to execute the API call\n4. Verify the response indicates success\n\n**Example:**\n```bash\ncurl -X POST ${baseUrl}/api/artifacts/insert-qa \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"ticketId\":\"0076\",\"title\":\"QA report for ticket 0076\",\"body_md\":\"# QA Report\\n\\n...\"}'\n```\n\n**DO NOT** just include JSON blocks in your message text - you must actually execute the API calls using terminal commands or HTTP requests.\n\n## QA completion: do not hand off to the user\n\nWhen the verdict is **PASS (OK to merge)**, QA must **complete the full workflow** — do not stop at a summary or \"next steps for the user.\"\n\n## Completion message format requirement\n\n**MANDATORY:** The final completion message to the user **must** include the ticket ID and an explicit PASS/FAIL outcome token in a consistent, easy-to-spot format.\n\n- **Format:** `QA RESULT: <PASS|FAIL> — <ticket-id>`\n- **Examples:**\n  - `QA RESULT: PASS — 0056`\n  - `QA RESULT: FAIL — 0056`\n- **Placement:** This must appear in the final summary message that QA sends to the user after completing all workflow steps (merge, branch deletion, ticket updates, etc.).\n- **Why:** HAL needs to reliably parse QA outcomes from chat transcripts. The format must be human-verifiable (no external tooling required) and consistently structured for automated interpretation.\n- **Verification:** A human can read the QA chat transcript in the app and immediately see the ticket ID and outcome without parsing complex prose.\n\n**If you are verifying from the feature branch** (normal workflow):\n\n1. **Complete AC Confirmation Checklist** — **MANDATORY:** Before proceeding, complete the AC Confirmation Checklist. Enumerate every Acceptance Criteria from the ticket, state \"Met\" or \"Not met\" for each with evidence. If any AC is not met, QA **MUST FAIL** and you must not proceed to step 2. See `.cursor/rules/ac-confirmation-checklist.mdc` for full requirements.\n2. **Store QA report in Supabase** — Make an HTTP POST request to `${baseUrl}/api/artifacts/insert-qa`. The QA report must include the AC Confirmation Checklist:\n   ```bash\n   curl -X POST ${baseUrl}/api/artifacts/insert-qa \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"ticketId\":\"0076\",\"title\":\"QA report for ticket 0076\",\"body_md\":\"<markdown>\"}'\n   ```\n3. **Update ticket body** (optional) — If needed, make an HTTP POST request to `${baseUrl}/api/tickets/update`:\n   ```bash\n   curl -X POST ${baseUrl}/api/tickets/update \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"ticketId\":\"0076\",\"body_md\":\"<updated markdown>\"}'\n   ```\n4. **Move ticket to Human in the Loop** — Make an HTTP POST request to `${baseUrl}/api/tickets/move`:\n   ```bash\n   curl -X POST ${baseUrl}/api/tickets/move \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"ticketId\":\"0076\",\"columnId\":\"col-human-in-the-loop\"}'\n   ```\n5. **Merge to main** — checkout `main`, merge the feature branch, push `main`.\n6. **Delete the feature branch** — local and remote (see `delete-branch-after-merge.mdc`).\n7. **Then** give your summary to the user. **The final message must include the AC Confirmation Checklist and:** `QA RESULT: PASS — <ticket-id>` (see \"Completion message format requirement\" above).\n\n**If you are verifying from `main`** (implementation was merged to main for QA access):\n\n1. **Complete AC Confirmation Checklist** — **MANDATORY:** Before proceeding, complete the AC Confirmation Checklist. Enumerate every Acceptance Criteria from the ticket, state \"Met\" or \"Not met\" for each with evidence. If any AC is not met, QA **MUST FAIL** and you must not proceed to step 2. See `.cursor/rules/ac-confirmation-checklist.mdc` for full requirements.\n2. **Store QA report in Supabase** — Make an HTTP POST request to `${baseUrl}/api/artifacts/insert-qa`. The QA report must include the AC Confirmation Checklist. Include a note in the report that verification was performed against `main`.\n3. **Update ticket body** (optional) — If needed, make an HTTP POST request to `${baseUrl}/api/tickets/update` to note that verification was performed against `main`.\n4. **Move ticket to Human in the Loop** — Make an HTTP POST request to `${baseUrl}/api/tickets/move`.\n5. **Then** give your summary to the user. **The final message must include the AC Confirmation Checklist and:** `QA RESULT: PASS — <ticket-id>` (see \"Completion message format requirement\" above).\n\nDo not give a summary with \"next steps\" or \"run these commands\" — QA performs the merge (or confirms main) and branch deletion where applicable. The user receives the completed result.\n\n- Use a commit subject that includes the ticket ID (e.g. `qa(0033): add QA report, move to Human in the Loop`).\n- **If verdict is FAIL:** Do not merge. Store the QA report in Supabase, then **YOU MUST move the ticket to the top of To-do** (`col-todo` column) via HAL API. **This is MANDATORY** - failing to move the ticket to To-do means the QA workflow is incomplete. Summarize findings and recommend a bugfix ticket (see `bugfix-tracking.mdc`). **The final message must include:** `QA RESULT: FAIL — <ticket-id>` (see \"Completion message format requirement\" above).\n  \n  **FAIL workflow:**\n  1. **Complete AC Confirmation Checklist** — **MANDATORY:** Complete the AC Confirmation Checklist even when QA fails. Enumerate every Acceptance Criteria from the ticket, state \"Met\" or \"Not met\" for each with evidence. This helps identify which ACs were not met. See `.cursor/rules/ac-confirmation-checklist.mdc` for full requirements.\n  2. **Store QA report in Supabase** — Make an HTTP POST request to `${baseUrl}/api/artifacts/insert-qa`. The QA report must include the AC Confirmation Checklist showing which ACs were not met:\n     ```bash\n     curl -X POST ${baseUrl}/api/artifacts/insert-qa \\\n       -H \"Content-Type: application/json\" \\\n       -d '{\"ticketId\":\"0076\",\"title\":\"QA report for ticket 0076\",\"body_md\":\"<markdown>\"}'\n     ```\n  3. **Move ticket to To-do** — **REQUIRED**: You MUST make an HTTP POST request to `${baseUrl}/api/tickets/move`. The ticket MUST be moved to `col-todo` when QA fails. This is not optional:\n     ```bash\n     curl -X POST ${baseUrl}/api/tickets/move \\\n       -H \"Content-Type: application/json\" \\\n       -d '{\"ticketId\":\"0076\",\"columnId\":\"col-todo\"}'\n     ```\n     **Note:** The goal is to move failed tickets to the **top** of the To-do column for priority handling. The current move API (`/api/tickets/move`) appends tickets to the end of the column. If the API is enhanced in the future to support position parameters, use position 0 or a negative value to place at the top. For now, moving to `col-todo` satisfies the requirement even if it's at the end initially.\n  4. **Then** give your summary to the user. **The final message must include the AC Confirmation Checklist and:** `QA RESULT: FAIL — <ticket-id>`.\n\n## HAL API Calls\n\n**CRITICAL: You must make actual HTTP API calls using terminal commands (curl) or run_terminal_cmd tool, not just include JSON blocks in your message.**\n\nAll Supabase operations must be executed via HTTP POST requests to HAL API endpoints.\n\n**Available API endpoints:**\n\n- **`POST /api/artifacts/insert-qa`** — Store QA report in Supabase\n  - Body: `{ ticketId: string, title: string, body_md: string }`\n  - Example: `curl -X POST ${baseUrl}/api/artifacts/insert-qa -H \"Content-Type: application/json\" -d '{\"ticketId\":\"0076\",\"title\":\"QA report\",\"body_md\":\"...\"}'`\n\n- **`POST /api/tickets/update`** — Update ticket body in Supabase\n  - Body: `{ ticketId: string, body_md: string }`\n  - Example: `curl -X POST ${baseUrl}/api/tickets/update -H \"Content-Type: application/json\" -d '{\"ticketId\":\"0076\",\"body_md\":\"...\"}'`\n\n- **`POST /api/tickets/move`** — Move ticket to different column\n  - Body: `{ ticketId: string, columnId: string }`\n  - Example: `curl -X POST ${baseUrl}/api/tickets/move -H \"Content-Type: application/json\" -d '{\"ticketId\":\"0076\",\"columnId\":\"col-todo\"}'`\n\n- **`POST /api/tickets/get`** — Fetch ticket content\n  - Body: `{ ticketId: string }`\n  - Example: `curl -X POST ${baseUrl}/api/tickets/get -H \"Content-Type: application/json\" -d '{\"ticketId\":\"0076\"}'`\n\n**How to use:**\n1. Read the API base URL from `.hal/api-base-url` (if it exists)\n2. Use `run_terminal_cmd` tool with `curl` to make HTTP POST requests\n3. Verify the response indicates success before proceeding\n4. **DO NOT** just include JSON blocks in your message - you must actually execute the API calls\n\n**Important:** The instructions previously said to \"include JSON blocks in your message\" - this is incorrect. You must make actual HTTP API calls.\n\n## Scope\n\n- Applies to any QA or verification of a **ticketed** task (ticket in Supabase).\n- Keep the report concise; use bullets and tables where appropriate.\n- All artifacts are stored in Supabase, not in `docs/audit/` folders.",
      "agentTypes": [
        "all",
        "qa-agent",
        "implementation-agent"
      ],
      "topicId": "qa-audit-report",
      "isBasic": true,
      "isSituational": false
    },
    {
      "path": "state-management-change-documentation.mdc",
      "name": "state management change documentation",
      "description": "Require agents to document and justify any changes to application state management in review artifacts",
      "alwaysApply": true,
      "content": "# State Management Change Documentation\n\n**MANDATORY:** Any change to application state management (stores, reducers, context, persistence, query cache, etc.) must be **called out and justified** in the agent's review artifact(s), so reviewers can quickly understand behavioral risk.\n\n## What is a \"State Management Change\"?\n\nA **state management change** is any modification to how application state is stored, accessed, updated, or persisted. This includes:\n\n### Examples of State Management Changes\n\n- **Store modifications** (Zustand, Redux, Pinia, etc.)\n  - Adding/removing/modifying store slices or actions\n  - Changing store structure or initial state\n  - Modifying store selectors or computed values\n\n- **Context provider changes** (React Context, Vue provide/inject, etc.)\n  - Adding/removing/modifying context providers\n  - Changing context value structure\n  - Modifying context consumers\n\n- **Persistence/hydration changes**\n  - Adding/removing localStorage/sessionStorage usage\n  - Changing persistence keys or serialization format\n  - Modifying hydration logic (loading persisted state on app start)\n  - Changing persistence scope (what gets persisted vs. ephemeral)\n\n- **Query cache changes** (React Query, SWR, Apollo, etc.)\n  - Modifying cache keys or invalidation strategies\n  - Changing cache time-to-live (TTL) or stale-while-revalidate settings\n  - Adding/removing cache mutations or optimistic updates\n\n- **Cross-tab synchronization changes**\n  - Adding/removing `storage` event listeners\n  - Modifying broadcast channel or shared worker usage\n  - Changing how state syncs across browser tabs/windows\n\n- **State migration changes**\n  - Adding migration logic for existing persisted state\n  - Changing state schema versions\n  - Modifying backward compatibility handling\n\n## When This Requirement Applies\n\nThis requirement applies to **all agents** when making changes that affect state management:\n\n- **Implementation agents** — Must document state management changes in their **PM Review artifact**\n- **QA agents** — Must verify that state management changes are properly documented and check the impact during QA review\n- **Project Manager agents** — Must ensure state management changes are called out in PM reviews\n\n## Required Documentation: PM Review Checklist\n\n**MANDATORY:** When an implementation agent makes any state management change, they **must** include the following checklist in their **PM Review artifact** (stored in Supabase with `artifactType: \"pm-review\"`).\n\n### Copy/Paste Checklist Template\n\n```markdown\n## State Management Changes\n\n**State management changes made:** [Yes / No]\n\nIf Yes, complete the following:\n\n### What Changed\n- [ ] Store/Context/Cache modified: [specify which and what changed]\n- [ ] Persistence logic modified: [specify what changed]\n- [ ] Migration logic added: [specify what changed]\n- [ ] Other state management change: [specify what changed]\n\n### Why This Change Was Necessary\n[Brief explanation of why the state management change was required]\n\n### Migration Considerations\n- [ ] Existing persisted state affected: [Yes / No]\n- [ ] Backward compatibility: [Maintained / Broken / N/A]\n- [ ] Migration path: [Describe how existing users' state will be handled, if applicable]\n\n### User-Visible Impact\n- [ ] State persists across sessions: [Yes / No / Changed]\n- [ ] State syncs across tabs: [Yes / No / Changed]\n- [ ] User data loss risk: [None / Low / Medium / High]\n- [ ] Performance impact: [None / Low / Medium / High]\n- [ ] Breaking changes: [None / Describe if any]\n\n### Code Locations\n[Cite specific file paths and line numbers where state management changes were made, per `.cursor/rules/code-location-citations.mdc`]\n```\n\n## QA Review Requirements\n\n**MANDATORY:** When QA agents review a ticket that includes state management changes, they **must**:\n\n1. **Verify the PM Review artifact includes the state management checklist** — If state management changes were made but the checklist is missing or incomplete, QA **MUST FAIL** the ticket.\n\n2. **Review the documented impact** — QA should verify:\n   - The \"What Changed\" section accurately describes the code changes\n   - The \"Why This Change Was Necessary\" provides adequate justification\n   - Migration considerations are addressed if applicable\n   - User-visible impact is accurately assessed\n\n3. **Include state management review in QA report** — QA reports should include a section confirming:\n   - State management changes were properly documented (or \"No state management changes\" if none were made)\n   - The documented impact assessment appears reasonable\n   - Any concerns about user data loss, breaking changes, or migration issues\n\n### QA Report Template Addition\n\nQA reports should include:\n\n```markdown\n## State Management Review\n\n**State management changes:** [Yes / No]\n\nIf Yes:\n- [ ] PM Review includes complete state management checklist\n- [ ] Documented changes match code review findings\n- [ ] Migration considerations addressed: [Yes / No / N/A]\n- [ ] User-visible impact assessment appears reasonable: [Yes / No]\n- [ ] Concerns identified: [None / List any concerns]\n```\n\n## Integration with Existing Workflows\n\n### PM Review Artifact\n\nThe state management checklist must be included in the **PM Review artifact** stored in Supabase:\n- **Artifact type:** `pm-review`\n- **Title format:** `PM Review for ticket <ticket-id>`\n- **Storage:** Via HAL API endpoint `/api/artifacts/insert-pm-review` (or equivalent)\n\n### QA Audit Report\n\nQA agents must verify state management documentation as part of their standard QA workflow (see `.cursor/rules/qa-audit-report.mdc`).\n\n## Scope\n\n- Applies to **all agents** (implementation, QA, PM) when state management changes are involved\n- The checklist must be **human-verifiable** — a reviewer can open the PM Review artifact and immediately see whether state management changes were made and their impact\n- When in doubt, **document the change** — it's better to over-document than to miss a state management change that could affect user experience\n",
      "agentTypes": [
        "all",
        "qa-agent",
        "implementation-agent",
        "project-manager"
      ],
      "topicId": "state-management-change-documentation",
      "isBasic": true,
      "isSituational": false,
      "topicMetadata": {
        "title": "State Management Change Documentation",
        "description": "Require agents to document and justify any changes to application state management in review artifacts",
        "agentTypes": [
          "all"
        ]
      }
    }
  ],
  "basic": [
    {
      "path": "agent-instructions.mdc",
      "name": "agent instructions",
      "description": "How to access agent instructions via HAL API",
      "alwaysApply": true,
      "content": "# Agent Instructions\n\nAgent instructions are stored in Supabase and accessed via HAL API endpoints. This file is an entry point to the instruction system.\n\n## Accessing Instructions\n\n### For Agents\n\nAgents should access instructions via HAL API endpoints (preferred) or directly from Supabase (fallback).\n\n**HAL API Endpoints:**\n\n- **Get all instructions:** `POST /api/instructions/get`\n  - Body: `{ repoFullName?: string, agentType?: string, includeBasic?: boolean, includeSituational?: boolean }`\n  - Returns: List of instructions filtered by agent type and instruction type\n\n- **Get specific topic:** `POST /api/instructions/get-topic`\n  - Body: `{ topicId: string, repoFullName?: string }`\n  - Returns: Full instruction content for a specific topic (used by `get_instruction_set` tool)\n\n- **Get instruction index:** `POST /api/instructions/get-index`\n  - Body: `{ repoFullName?: string }`\n  - Returns: Instruction index metadata with available topics\n\n**Example (get basic instructions):**\n```javascript\nconst baseUrl = (await readFile('.hal/api-base-url', 'utf8')).trim()\nconst res = await fetch(`${baseUrl}/api/instructions/get`, {\n  method: 'POST',\n  headers: { 'Content-Type': 'application/json' },\n  body: JSON.stringify({\n    agentType: 'project-manager',\n    includeBasic: true,\n    includeSituational: false,\n  }),\n})\nconst result = await res.json()\nif (result.success) {\n  // result.instructions contains the basic instructions\n}\n```\n\n**Example (get specific topic):**\n```javascript\nconst res = await fetch(`${baseUrl}/api/instructions/get-topic`, {\n  method: 'POST',\n  headers: { 'Content-Type': 'application/json' },\n  body: JSON.stringify({\n    topicId: 'auditability-and-traceability',\n  }),\n})\nconst result = await res.json()\nif (result.success) {\n  // result.content contains the full instruction content\n}\n```\n\n### Instruction Structure\n\nInstructions are organized into:\n\n1. **Basic Instructions** - Always loaded for all agents (minimal core instructions)\n2. **Situational Instructions** - Available on-demand via `get_instruction_set` tool\n\n### For Users\n\nUsers can browse and edit instructions in the HAL app:\n- Click \"Agent Instructions\" button in the header\n- Browse the instruction hierarchy (All Agents → Agent → Instruction)\n- Click \"Edit\" to modify instructions (saves directly to Supabase)\n\n### Instruction Storage\n\n- **Storage:** Supabase `agent_instructions` and `agent_instruction_index` tables\n- **Editing:** Via HAL app UI (writes to Supabase)\n- **Access:** Via HAL API endpoints (no direct Supabase access needed)\n\nSee `.cursor/rules/agent-supabase-api-paradigm.mdc` for full API endpoint documentation.\n\n## Moving Tickets After Implementation\n\n**⚠️ CRITICAL MANDATORY STEP - DO NOT SKIP THIS ⚠️**\n\n**MANDATORY:** After completing implementation work, implementation agents **MUST** move the ticket to **Ready for QA** using the HAL API. This is **not optional** - failing to move the ticket to Ready for QA means the implementation workflow is incomplete and the ticket will remain in the wrong column.\n\n**YOU MUST MOVE THE TICKET BEFORE SENDING YOUR COMPLETION SUMMARY. DO NOT SAY \"DONE\" OR \"COMPLETE\" WITHOUT MOVING THE TICKET FIRST.**\n\n**Move ticket to Ready for QA (REQUIRED BEFORE COMPLETION):**\n```javascript\nconst baseUrl = (await readFile('.hal/api-base-url', 'utf8')).trim()\nconst res = await fetch(`${baseUrl}/api/tickets/move`, {\n  method: 'POST',\n  headers: { 'Content-Type': 'application/json' },\n  body: JSON.stringify({\n    ticketId: '0167', // The ticket ID (e.g., '0167' for HAL-0167)\n    columnId: 'col-qa', // Ready for QA column\n  }),\n})\nconst result = await res.json()\nif (result.success) {\n  // Ticket moved successfully to position result.position\n  // NOW you can send your completion summary\n} else {\n  // If move fails, DO NOT send completion summary - fix the issue first\n  throw new Error(`Failed to move ticket: ${result.error}`)\n}\n```\n\n**Ticket ID formats:**\nThe `/api/tickets/move` endpoint accepts multiple ticket ID formats for flexibility:\n- Numeric ID: `'172'` (the actual id field value)\n- With leading zeros: `'0172'` (will be normalized automatically)\n- Display ID: `'HAL-0172'` (will be resolved to the numeric id)\n\nThe API automatically handles these formats by trying multiple lookup strategies, so you can use whichever format is most convenient. The API will find the ticket regardless of format and use the ticket's primary key (pk) for the update to ensure reliability.\n\n**When to move (MANDATORY WORKFLOW):**\n1. ✅ After all code changes are committed and pushed\n2. ✅ After all required artifacts are stored (if applicable)\n3. ✅ **MOVE THE TICKET TO READY FOR QA** (use the API call above)\n4. ✅ **THEN** send your final \"implementation complete\" summary message\n\n**CRITICAL WORKFLOW RULE:** \n- **DO NOT** send a completion summary or \"done\" message without first moving the ticket to Ready for QA\n- **DO NOT** mark the ticket as complete in your message if you haven't moved it\n- The ticket move is **part of the completion workflow**, not an optional step\n- If the move fails, **DO NOT** proceed with completion - fix the issue and retry the move\n\n**Available column IDs:**\n- `col-unassigned` - Unassigned\n- `col-todo` - To-do\n- `col-doing` - Doing (Active Work)\n- `col-qa` - Ready for QA\n- `col-human-in-the-loop` - Human in the Loop\n- `col-process-review` - Process Review\n- `col-done` - Done\n- `col-wont-implement` - Will Not Implement\n\n**Note:** The HAL API endpoint `/api/tickets/move` uses server-side Supabase credentials, so agents don't need to provide credentials in the request body. The API uses the ticket's primary key (pk) for updates to ensure reliable ticket movement regardless of the ticket ID format provided.\n",
      "agentTypes": [
        "all",
        "implementation-agent",
        "project-manager",
        "process-review-agent"
      ],
      "topicId": "agent-instructions",
      "isBasic": true,
      "isSituational": false,
      "topicMetadata": {
        "title": "Agent Instructions Entry Point",
        "description": "Entry point for agent instructions - load basic rules from Supabase",
        "agentTypes": [
          "all"
        ]
      }
    },
    {
      "path": "code-citation-requirements.mdc",
      "name": "code citation requirements",
      "description": "Require agents to cite specific file paths and line numbers when referencing code locations",
      "alwaysApply": true,
      "content": "# Code Citation Requirements\n\nWhen agents reference \"where something is implemented\" or claim where key functionality exists, they **must** cite concrete code locations using file paths and (when feasible) line numbers or symbol names. This enables reviewers to verify claims quickly without searching the codebase.\n\n## Mandatory Citation Format\n\n**Minimum acceptable citation formats:**\n\n1. **File path with line range:** `src/foo.ts:42-61`\n2. **File path with single line:** `src/foo.ts:42`\n3. **File path with symbol name:** `src/foo.ts — function bar()` or `src/foo.ts — class MyComponent`\n4. **File path with line and symbol:** `src/foo.ts:42 — function bar()`\n\n**Examples:**\n- ✅ `src/api/tickets.ts:123-145` — implementation of ticket syncing\n- ✅ `components/KanbanBoard.tsx:42` — column rendering logic\n- ✅ `src/utils/validation.ts — function validateTicket()` — validation rules\n- ✅ `src/hooks/useTickets.ts:78-92 — useEffect hook` — data fetching\n- ❌ \"in the tickets API file\" — too vague\n- ❌ \"tickets.ts\" — missing path context\n- ❌ \"the validation function\" — no file reference\n\n## Required Contexts\n\nThis requirement applies to all of the following contexts:\n\n### 1. Implementation Summaries and Worklogs\n\nWhen implementation agents document what was implemented, they must cite specific locations:\n\n**Example (worklog):**\n```markdown\n## Changes Made\n\n- Added ticket syncing logic in `src/api/tickets.ts:123-145` — `syncTickets()` function\n- Updated column rendering in `components/KanbanBoard.tsx:42-67` — `renderColumns()` method\n- Fixed validation in `src/utils/validation.ts:89-102 — validateTicket()` function\n```\n\n### 2. QA Reports\n\nWhen QA agents review code and report findings, they must cite specific locations:\n\n**Example (QA report code review section):**\n```markdown\n## Code Review\n\n| Requirement | Implementation | Status |\n|------------|----------------|--------|\n| Ticket syncing | `src/api/tickets.ts:123-145 — syncTickets()` | ✅ PASS |\n| Column rendering | `components/KanbanBoard.tsx:42-67` | ✅ PASS |\n| Validation | `src/utils/validation.ts:89-102 — validateTicket()` | ⚠️ FAIL — missing null check |\n```\n\n### 3. PM Guidance\n\nWhen Project Manager agents answer questions like \"Where is X implemented?\" or \"How does Y work?\", they must cite specific locations:\n\n**Example (PM response):**\n```markdown\nTicket syncing is implemented in `src/api/tickets.ts:123-145` in the `syncTickets()` function. The function handles:\n- Fetching tickets from Supabase (`src/api/tickets.ts:130-138`)\n- Updating local state (`src/api/tickets.ts:140-145`)\n```\n\n## Exceptions: When Line Numbers Are Unreliable\n\nWhen line numbers are unreliable or unstable (e.g., generated code, minified bundles, frequently changing files), cite the nearest stable anchor instead:\n\n**Acceptable alternatives:**\n- **Symbol name + file path:** `src/generated/api.ts — export function fetchTickets()`\n- **Exported function/class:** `src/api/index.ts — export { syncTickets }`\n- **Route ID or path:** `src/routes.ts — route id: 'tickets'`\n- **Component name:** `components/TicketCard.tsx — <TicketCard /> component`\n- **Configuration key:** `config/app.config.ts — tickets.syncInterval`\n\n**Examples:**\n- ✅ `dist/bundle.js — function syncTickets()` (minified bundle)\n- ✅ `src/generated/types.ts — interface Ticket` (generated file)\n- ✅ `src/routes.ts — route: '/tickets'` (routing config)\n- ❌ `dist/bundle.js:1234` (line number in minified code is unreliable)\n\n**When in doubt:** Prefer symbol names, exported identifiers, or stable configuration keys over line numbers in generated or frequently-changing files.\n\n## Enforcement\n\n- **Implementation agents:** Must include citations in worklogs, plans, and implementation summaries.\n- **QA agents:** Must include citations in code review sections of QA reports (see `.cursor/rules/qa-audit-report.mdc`).\n- **PM agents:** Must include citations when answering \"where is X implemented?\" questions.\n\n**Reviewers should verify:** All code location claims can be verified by navigating to the cited file path and (when provided) line number or symbol name.\n",
      "agentTypes": [
        "all",
        "qa-agent",
        "implementation-agent",
        "project-manager"
      ],
      "topicId": "code-citation-requirements",
      "isBasic": true,
      "isSituational": false,
      "topicMetadata": {
        "title": "Code Citation Requirements",
        "description": "Require agents to cite specific file paths and line numbers when referencing code locations",
        "agentTypes": [
          "all"
        ]
      }
    },
    {
      "path": "code-location-citations.mdc",
      "name": "code location citations",
      "description": "Require agents to cite specific file paths and line numbers/symbols when referencing where functionality is implemented",
      "alwaysApply": true,
      "content": "# Code Location Citations\n\nWhen an agent references \"where something is implemented\" or claims where key functionality exists, they **must** cite concrete code locations that reviewers can verify quickly.\n\n## Required Citation Format\n\n**Minimum acceptable citation formats:**\n\n- **File path with line range:** `src/foo.ts:42-61`\n- **File path with function/class name:** `src/foo.ts — function bar()`\n- **File path with symbol:** `src/foo.ts — class MyComponent`\n- **File path with route/component ID:** `src/routes.ts — route id: \"dashboard\"`\n\n**Examples:**\n- ✅ `src/components/Button.tsx:15-23` (line range)\n- ✅ `src/utils/api.ts — function fetchUser()` (symbol name)\n- ✅ `src/routes.ts:42 — route id: \"settings\"` (route identifier)\n- ✅ `src/App.tsx — component App` (component name)\n- ❌ `src/components/Button.tsx` (missing line/symbol)\n- ❌ `the Button component` (no file path)\n\n## When Citations Are Required\n\nCitations are **mandatory** in these contexts:\n\n1. **Implementation summaries/worklogs** — When describing what was implemented or where changes were made\n2. **QA reports** — When reviewing code and referencing where functionality exists\n3. **PM guidance** — When answering \"where is X implemented?\" or similar questions\n\n## Exceptions: Unreliable Line Numbers\n\nIf line numbers are unreliable or unstable (e.g., generated code, minified bundles, auto-generated files), cite the **nearest stable anchor** instead:\n\n- **Symbol name** (exported function, class, constant)\n- **Route ID** or **component name**\n- **Export identifier**\n- **File path** (always required, even when line numbers aren't)\n\n**Examples of stable anchors:**\n- `src/generated/api.ts — export function createUser()` (generated file, use symbol)\n- `dist/bundle.js — function handleClick()` (minified, use symbol)\n- `src/routes.ts — route id: \"dashboard\"` (route identifier)\n\n**Always include the file path** even when using stable anchors instead of line numbers.\n\n## Scope\n\n- Applies to **all agents** (implementation, QA, PM) when referencing code locations\n- Citations must be **human-verifiable** — a reviewer should be able to open the file and find the referenced location\n- When in doubt, provide **more specific citations** (line numbers + symbol names) rather than less\n",
      "agentTypes": [
        "all"
      ],
      "topicId": "code-location-citations",
      "isBasic": true,
      "isSituational": false,
      "topicMetadata": {
        "title": "Code Location Citations",
        "description": "Require agents to cite concrete code locations that reviewers can verify quickly",
        "agentTypes": [
          "all"
        ]
      }
    },
    {
      "path": "heading-parsing-pitfalls.mdc",
      "name": "heading parsing pitfalls",
      "description": "Guide for agents to produce headings that HAL can parse and render correctly",
      "alwaysApply": true,
      "content": "# Heading parsing pitfalls (and how to avoid them)\n\nWhen creating tickets or writing documentation, agents must produce headings that HAL can parse and render correctly. This guide covers common pitfalls and how to avoid them.\n\n## Pitfall 1: Inconsistent heading levels\n\n**Problem:** Using `#` (H1) or `###` (H3) when `##` (H2) is required, or skipping heading levels (e.g., going from `##` to `####`).\n\n**Why this fails:** HAL's parsing logic expects specific heading levels. Required ticket sections must use `##` (H2) to be recognized correctly.\n\n**❌ Bad examples:**\n```markdown\n# Goal (one sentence)\n\nAdd a feature.\n\n### Acceptance criteria\n\n- [ ] Item 1\n```\n\n```markdown\n## Goal (one sentence)\n\nAdd a feature.\n\n#### Acceptance criteria\n\n- [ ] Item 1\n```\n\n**✅ Good example:**\n```markdown\n## Goal (one sentence)\n\nAdd a feature.\n\n## Acceptance criteria (UI-only)\n\n- [ ] Item 1\n```\n\n**Fix:** Always use `##` (H2) for required ticket sections. Maintain consistent heading hierarchy throughout the document.\n\n## Pitfall 2: Ambiguous \"pseudo-headings\" instead of real markdown headings\n\n**Problem:** Using bold text (`**Section Name:**`) or text with colons (`Section Name:`) when a real markdown heading is intended.\n\n**Why this fails:** HAL's parsing logic looks for markdown heading syntax (`## Section Name`), not bold text or colons. Pseudo-headings won't be recognized as section boundaries.\n\n**❌ Bad examples:**\n```markdown\n**Goal (one sentence):**\n\nAdd a feature.\n\n**Acceptance criteria (UI-only):**\n\n- [ ] Item 1\n```\n\n```markdown\nGoal (one sentence):\n\nAdd a feature.\n\nAcceptance criteria (UI-only):\n\n- [ ] Item 1\n```\n\n**✅ Good example:**\n```markdown\n## Goal (one sentence)\n\nAdd a feature.\n\n## Acceptance criteria (UI-only)\n\n- [ ] Item 1\n```\n\n**Fix:** Use proper markdown heading syntax (`## Section Name`) instead of bold text or plain text with colons.\n\n## Pitfall 3: Required ticket headings don't match canonical text exactly\n\n**Problem:** Using variations like \"Goal\" instead of \"Goal (one sentence)\", or \"Acceptance criteria\" instead of \"Acceptance criteria (UI-only)\".\n\n**Why this fails:** HAL's parsing logic uses case-sensitive, exact text matching. Headings must match the canonical format exactly to be recognized.\n\n**❌ Bad examples:**\n```markdown\n## Goal\n\nAdd a feature.\n\n## Human-verifiable deliverable\n\nUser sees a button.\n\n## Acceptance criteria\n\n- [ ] Item 1\n```\n\n```markdown\n## Goal (one sentence)\n\nAdd a feature.\n\n## Human-verifiable deliverable (UI only)\n\nUser sees a button.\n\n## Acceptance Criteria (UI-only)\n\n- [ ] Item 1\n```\n\n**✅ Good example:**\n```markdown\n## Goal (one sentence)\n\nAdd a feature.\n\n## Human-verifiable deliverable (UI-only)\n\nUser sees a button.\n\n## Acceptance criteria (UI-only)\n\n- [ ] Item 1\n```\n\n**Fix:** Use the exact canonical text for required ticket sections:\n- `## Goal (one sentence)`\n- `## Human-verifiable deliverable (UI-only)`\n- `## Acceptance criteria (UI-only)`\n- `## Constraints`\n- `## Non-goals`\n\n## Pitfall 4: Duplicating the same top-level heading multiple times\n\n**Problem:** Including multiple `# Ticket` blocks or repeating the same top-level section heading.\n\n**Why this fails:** HAL's parsing logic expects a single, well-structured document. Duplicate headings can cause parsing confusion and make sections ambiguous.\n\n**❌ Bad example:**\n```markdown\n# Ticket\n\n## Goal (one sentence)\n\nAdd a feature.\n\n# Ticket\n\n## Goal (one sentence)\n\nAdd another feature.\n```\n\n**✅ Good example:**\n```markdown\n## Goal (one sentence)\n\nAdd a feature.\n\n## Human-verifiable deliverable (UI-only)\n\nUser sees a button.\n\n## Acceptance criteria (UI-only)\n\n- [ ] Item 1\n- [ ] Item 2\n```\n\n**Fix:** Use each heading only once. If you need to group related content, use subheadings (`###`) or organize content within a single section.\n\n## Pitfall 5: Using plain bullets instead of checkboxes in Acceptance criteria\n\n**Problem:** Using `- Item` or `* Item` instead of `- [ ] Item` for Acceptance criteria items.\n\n**Why this fails:** HAL's Ready-to-start checklist requires Acceptance criteria to use checkbox format (`- [ ]`) so items can be tracked and verified. Plain bullets won't pass validation.\n\n**❌ Bad examples:**\n```markdown\n## Acceptance criteria (UI-only)\n\n- User sees a button\n- Button is clickable\n- Clicking shows a message\n```\n\n```markdown\n## Acceptance criteria (UI-only)\n\n* User sees a button\n* Button is clickable\n* Clicking shows a message\n```\n\n**✅ Good example:**\n```markdown\n## Acceptance criteria (UI-only)\n\n- [ ] User sees a button labeled \"Save\" in the header\n- [ ] Button is clickable and responds to clicks\n- [ ] Clicking the button shows a success message in the UI\n```\n\n**Fix:** Always use checkbox format (`- [ ]`) for Acceptance criteria items. Each item should be UI-verifiable (a human can confirm by looking at the UI or running a manual test).\n\n## Copy/paste examples\n\n### Good: Minimal ticket skeleton that passes Definition of Ready\n\n```markdown\n## Goal (one sentence)\n\nAdd a dark mode toggle button to the settings page that persists the user's preference.\n\n## Human-verifiable deliverable (UI-only)\n\nA non-technical user opens the app, navigates to Settings, sees a \"Dark mode\" toggle switch, clicks it, and observes the entire app UI changes from light to dark theme. The preference persists after page refresh.\n\n## Acceptance criteria (UI-only)\n\n- [ ] Settings page displays a \"Dark mode\" toggle switch that is clearly visible and clickable\n- [ ] Clicking the toggle immediately changes the app theme from light to dark (or vice versa) with a smooth transition\n- [ ] The selected theme preference persists after page refresh (the toggle state matches the current theme on reload)\n\n## Constraints\n\n- Keep this task as small as possible while still producing a **human-verifiable** UI change.\n- Verification must require **no external tools** (no terminal, no devtools, no console).\n\n## Non-goals\n\n- Theme customization beyond light/dark (no color pickers or advanced theming)\n- Per-component theme overrides (global theme only)\n```\n\n**Why this is good:**\n- All headings use `##` (H2) consistently\n- Headings match canonical text exactly\n- Acceptance criteria use checkbox format (`- [ ]`)\n- No placeholders or pseudo-headings\n- All sections are present and properly formatted\n\n### Bad: Common failure mode and corrected version\n\n**❌ Bad example (multiple pitfalls):**\n```markdown\n# Ticket\n\n**Goal:** Add dark mode toggle\n\n### Human-verifiable deliverable\n\nUser sees toggle in settings.\n\n## Acceptance criteria\n\n- User sees toggle\n- Toggle works\n- Preference saves\n\n## Constraints\n\n- Use existing theme system\n\n## Non-goals\n\n- Advanced theming\n```\n\n**Problems:**\n1. Uses `# Ticket` (H1) instead of starting with `## Goal`\n2. Uses bold pseudo-heading `**Goal:**` instead of `## Goal (one sentence)`\n3. Uses `###` (H3) for \"Human-verifiable deliverable\" instead of `##`\n4. Missing \"(one sentence)\" and \"(UI-only)\" suffixes in headings\n5. Uses plain bullets (`-`) instead of checkboxes (`- [ ]`) in Acceptance criteria\n6. Acceptance criteria items are not UI-verifiable (too vague)\n\n**✅ Corrected version:**\n```markdown\n## Goal (one sentence)\n\nAdd a dark mode toggle button to the settings page that persists the user's preference.\n\n## Human-verifiable deliverable (UI-only)\n\nA non-technical user opens the app, navigates to Settings, sees a \"Dark mode\" toggle switch, clicks it, and observes the entire app UI changes from light to dark theme. The preference persists after page refresh.\n\n## Acceptance criteria (UI-only)\n\n- [ ] Settings page displays a \"Dark mode\" toggle switch that is clearly visible and clickable\n- [ ] Clicking the toggle immediately changes the app theme from light to dark (or vice versa) with a smooth transition\n- [ ] The selected theme preference persists after page refresh (the toggle state matches the current theme on reload)\n\n## Constraints\n\n- Use existing theme system (no new CSS framework)\n- Theme preference must be stored in localStorage\n\n## Non-goals\n\n- Theme customization beyond light/dark (no color pickers or advanced theming)\n- Per-component theme overrides (global theme only)\n```\n\n**Why this is correct:**\n- All headings use `##` (H2) consistently\n- Headings match canonical text exactly: \"Goal (one sentence)\", \"Human-verifiable deliverable (UI-only)\", \"Acceptance criteria (UI-only)\"\n- Acceptance criteria use checkbox format (`- [ ]`)\n- All items are UI-verifiable with specific, testable descriptions\n- No pseudo-headings or placeholders\n\n## Summary\n\nTo produce headings that HAL can parse correctly:\n\n1. **Use `##` (H2) consistently** for required ticket sections\n2. **Use proper markdown heading syntax** (`## Section Name`), not bold text or colons\n3. **Match canonical text exactly** (case-sensitive): \"Goal (one sentence)\", \"Human-verifiable deliverable (UI-only)\", \"Acceptance criteria (UI-only)\"\n4. **Avoid duplicate top-level headings** — use each heading only once\n5. **Use checkbox format** (`- [ ]`) for Acceptance criteria items, not plain bullets\n\nFollowing these guidelines ensures your tickets will pass HAL's Definition of Ready validation and be correctly parsed and rendered in the UI.\n",
      "agentTypes": [
        "all"
      ],
      "topicId": "heading-parsing-pitfalls",
      "isBasic": true,
      "isSituational": false
    },
    {
      "path": "key-decisions-summary.mdc",
      "name": "key decisions summary",
      "description": "Require agents to include a \"Key decisions\" summary in completion write-ups so reviewers can understand tradeoffs without re-reading entire worklogs",
      "alwaysApply": true,
      "content": "# Key Decisions Summary Requirement\n\n**MANDATORY:** All agent completion write-ups must include a short, explicit **\"Key decisions\"** summary (2–6 bullets) so reviewers can quickly understand tradeoffs and design choices without re-reading the entire worklog or diff.\n\n## When This Requirement Applies\n\nThis requirement applies to **all agents** when completing work:\n\n- **Implementation agents** — Must include \"Key decisions\" in both the **PM Review artifact** and the **final chat completion summary**\n- **QA agents** — Must verify that the \"Key decisions\" section exists and is complete during review\n- **Project Manager agents** — Must check for \"Key decisions\" section when reviewing implementation artifacts\n\n## Required Content: Key Decisions Section\n\n**MANDATORY:** Implementation agents **must** include a \"Key decisions\" section in:\n\n1. **PM Review artifact** (stored in Supabase with `artifactType: \"pm-review\"`)\n2. **Final chat completion summary** (the \"done\" message sent to the user)\n\n### Format\n\nThe \"Key decisions\" section should be a bulleted list (2–6 bullets) that explains:\n\n- **Why approach A was chosen over approach B** (e.g., \"Used Supabase API endpoint instead of direct database access for better error handling and validation\")\n- **Any tradeoffs or risks** (e.g., \"Chose synchronous validation over async to simplify error handling, but this may block UI for large datasets\")\n- **Design choices that affect maintainability** (e.g., \"Stored instructions in Supabase rather than file system to enable runtime updates without deployments\")\n- **Performance or scalability considerations** (e.g., \"Implemented client-side caching to reduce API calls, with 5-minute TTL to balance freshness and performance\")\n- **Integration decisions** (e.g., \"Updated existing instruction update endpoint rather than creating new one to maintain API consistency\")\n\n### Example: Good Key Decisions Section\n\n```markdown\n## Key Decisions\n\n- **Stored instructions in Supabase instead of file system** — Enables runtime updates via HAL UI without requiring deployments or code changes. Tradeoff: Requires Supabase connection, but this is already a dependency for the project.\n\n- **Updated existing `/api/instructions/update` endpoint** — Rather than creating a new endpoint, extended the existing one to maintain API consistency. This keeps the instruction update workflow unified.\n\n- **Added \"Key decisions\" requirement to all agent types** — Not just implementation agents, but also QA and PM agents need to check for this section. This ensures comprehensive review coverage.\n\n- **Included example in instruction file** — Provides concrete guidance on what constitutes a good \"Key decisions\" bullet, helping agents understand the expected level of detail and tradeoff explanation.\n\n- **Required in both PM Review artifact and chat summary** — Ensures visibility in both the structured artifact (for audit trail) and the conversational summary (for immediate review).\n```\n\n### Example: Poor Key Decisions Section (Too Vague)\n\n```markdown\n## Key Decisions\n\n- Used Supabase for storage\n- Updated the API\n- Added requirements\n```\n\n**Why this is poor:** Doesn't explain tradeoffs, alternatives considered, or reasoning. Reviewers can't understand the \"why\" without reading the entire worklog.\n\n## Implementation Agent Requirements\n\n**MANDATORY:** When completing a ticket, implementation agents **must**:\n\n1. **Include \"Key decisions\" in PM Review artifact:**\n   - Store the PM Review artifact via HAL API: `POST /api/artifacts/insert-implementation`\n   - Artifact type: `pm-review`\n   - Title format: `PM Review for ticket <ticket-id>`\n   - The artifact body must include a \"Key decisions\" section with 2–6 bullets\n\n2. **Include \"Key decisions\" in final chat completion summary:**\n   - When sending the completion message (the \"done\" summary), include a \"Key decisions\" section\n   - This can be a brief summary (2–4 bullets) that highlights the most important decisions\n   - The full detailed version should be in the PM Review artifact\n\n### PM Review Artifact Template\n\n```markdown\n# PM Review for ticket <ticket-id>\n\n[Other PM Review content...]\n\n## Key Decisions\n\n- [Bullet 1: Why approach A over B, tradeoffs, risks]\n- [Bullet 2: Design choice affecting maintainability]\n- [Bullet 3: Performance/scalability consideration]\n- [Bullet 4: Integration decision]\n- [Bullet 5-6: Additional important decisions]\n\n[Other PM Review content...]\n```\n\n### Final Chat Summary Template\n\n```markdown\n## Summary\n\n[Brief summary of what was implemented...]\n\n## Key Decisions\n\n- [Most important decision 1]\n- [Most important decision 2]\n- [Most important decision 3]\n\nTicket <ticket-id> implementation completed and moved to QA.\n```\n\n## QA Agent Requirements\n\n**MANDATORY:** When QA agents review a ticket, they **must**:\n\n1. **Verify \"Key decisions\" section exists** — Check both:\n   - PM Review artifact (via HAL API: `POST /api/artifacts/get`)\n   - Final chat completion summary (if available in conversation history)\n\n2. **Verify \"Key decisions\" content quality** — The section should:\n   - Contain 2–6 bullets (not too few, not too many)\n   - Explain tradeoffs or alternatives considered\n   - Provide reasoning, not just descriptions\n   - Be specific enough that reviewers understand the \"why\" without reading the entire worklog\n\n3. **Include \"Key decisions\" review in QA report** — QA reports should include a section confirming:\n   - \"Key decisions\" section exists in PM Review artifact: [Yes / No]\n   - \"Key decisions\" section exists in completion summary: [Yes / No / N/A]\n   - Content quality: [Pass / Fail / Needs improvement]\n   - If missing or incomplete, QA **MUST FAIL** the ticket\n\n### QA Report Template Addition\n\nQA reports should include:\n\n```markdown\n## Key Decisions Review\n\n**Key decisions section in PM Review artifact:** [Yes / No]\n\n**Key decisions section in completion summary:** [Yes / No / N/A]\n\n**Content quality:**\n- [ ] Contains 2–6 bullets: [Yes / No]\n- [ ] Explains tradeoffs or alternatives: [Yes / No]\n- [ ] Provides reasoning (not just descriptions): [Yes / No]\n- [ ] Specific enough to understand \"why\" without reading full worklog: [Yes / No]\n\n**Overall assessment:** [Pass / Fail / Needs improvement]\n\n**If missing or incomplete:** QA **MUST FAIL** the ticket and request the implementation agent to add the \"Key decisions\" section.\n```\n\n## Project Manager Agent Requirements\n\n**MANDATORY:** When Project Manager agents review implementation artifacts, they **must**:\n\n1. **Check for \"Key decisions\" section** — Verify it exists in the PM Review artifact\n\n2. **Verify completeness** — Ensure the section:\n   - Contains 2–6 bullets\n   - Explains tradeoffs and reasoning\n   - Helps reviewers understand design choices quickly\n\n3. **Flag missing sections** — If \"Key decisions\" is missing or incomplete, PM agents should:\n   - Note this in their review\n   - Request the implementation agent to add it\n   - Consider this a blocker for ticket completion\n\n## Integration with Existing Workflows\n\n### PM Review Artifact\n\nThe \"Key decisions\" section must be included in the **PM Review artifact** stored in Supabase:\n- **Artifact type:** `pm-review`\n- **Title format:** `PM Review for ticket <ticket-id>`\n- **Storage:** Via HAL API endpoint `/api/artifacts/insert-implementation` with `artifactType: \"pm-review\"`\n\n### Final Chat Completion Summary\n\nThe \"Key decisions\" section must also be included in the **final chat completion summary** (the \"done\" message):\n- This is the message sent when the implementation agent completes work\n- Can be a brief version (2–4 bullets) highlighting the most important decisions\n- The full detailed version should be in the PM Review artifact\n\n### QA Audit Report\n\nQA agents must verify \"Key decisions\" documentation as part of their standard QA workflow.\n\n## Scope\n\n- Applies to **all agents** (implementation, QA, PM) when completing or reviewing work\n- The \"Key decisions\" section must be **human-verifiable** — a reviewer can open the PM Review artifact and immediately see the key decisions and tradeoffs\n- When in doubt, **include more detail** — it's better to over-explain tradeoffs than to leave reviewers guessing why certain approaches were chosen\n",
      "agentTypes": [
        "all",
        "qa-agent",
        "implementation-agent",
        "project-manager"
      ],
      "topicId": "key-decisions-summary",
      "isBasic": true,
      "isSituational": false,
      "topicMetadata": {
        "title": "Key Decisions Summary Requirement",
        "description": "Require agents to include a \"Key decisions\" summary in completion write-ups so reviewers can understand tradeoffs without re-reading entire worklogs",
        "agentTypes": [
          "all"
        ]
      }
    },
    {
      "path": "qa-audit-report.mdc",
      "name": "qa audit report",
      "description": "QA agents must store QA reports in Supabase via HAL API",
      "alwaysApply": true,
      "content": "# QA Audit Report (QA Agents)\n\nWhen you **QA a ticket** (e.g. user asks to \"QA\", \"verify\", or \"check\" a ticket that is allegedly complete), you **must** store a QA report in Supabase via HAL's API endpoints.\n\n## Cloud QA workflow context\n\nIn cloud environments, QA agents may not have access to feature branches (only `main`). When this is the case, the implementation agent merges the feature branch to `main` before QA begins. QA must then verify from `main` rather than attempting to check out a feature branch. This workflow is indicated when the ticket states \"merged to `main` for QA access\" or similar language.\n\n## Which branch to use (decision rule)\n\n- **If the ticket or prompt states that the implementation was \"merged to main for QA access\"** (or that code is on `main` for QA): \n  - You **must** verify from the **`main`** branch. \n  - Do **not** attempt to locate, check out, or use the feature branch.\n  - **Step 1:** Pull the latest `main` branch: `git checkout main && git pull origin main`\n  - **Step 2:** Perform QA on `main` (code review and verification).\n  - **Step 3:** Record in the QA report that verification was performed against `main` (e.g. \"Verified on `main`; implementation was merged to main for QA access.\").\n  - **Step 4:** Store the QA report in Supabase via HAL API (see \"Storing QA report\" below).\n  - **Step 5:** Move ticket to Human in the Loop via HAL API, then provide summary.\n- **Otherwise:** use the feature branch named in the ticket's QA → Branch field (or the branch you were launched on). Perform QA on that branch, then follow the full workflow (merge to main, delete branch, etc.).\n\n**Important:** When QA cannot access feature branches (cloud QA workflow), the implementation agent merges the feature branch to `main` before QA. In this case, QA must verify from `main` and record this in the QA report stored in Supabase.\n\n## Required implementation artifacts (must be present before QA)\n\n**MANDATORY:** Before performing any QA work, you **must** verify that all required implementation artifacts are present in Supabase. If any are missing, QA **must fail immediately** without attempting code review or verification.\n\n**Required implementation artifacts:**\n1. **Plan artifact** (`artifactType: \"plan\"`, title: `Plan for ticket <ticket-id>`)\n2. **Worklog artifact** (`artifactType: \"worklog\"`, title: `Worklog for ticket <ticket-id>`)\n3. **Changed Files artifact** (`artifactType: \"changed-files\"`, title: `Changed Files for ticket <ticket-id>`)\n   - **MANDATORY:** This artifact is REQUIRED on every ticket and must NEVER be omitted or left blank.\n   - **Content requirements:** The Changed Files artifact must be NON-EMPTY and contain substantive content:\n     - **When files changed:** Must list all file paths that were created/modified/deleted, with a brief one-line description of what changed in each file.\n     - **When no files changed:** Must explicitly state \"No files changed.\" followed by a brief explanation (e.g., \"Docs-only ticket handled via Supabase updates\", \"Investigation only\", \"Repro failed; no code changes made\").\n   - **Process failure:** If the Changed Files artifact is missing, blank, or contains only a title with no substantive content, this is a PROCESS FAILURE and QA MUST FAIL immediately.\n4. **Decisions artifact** (`artifactType: \"decisions\"`, title: `Decisions for ticket <ticket-id>`)\n5. **Verification artifact** (`artifactType: \"verification\"`, title: `Verification for ticket <ticket-id>`)\n6. **PM Review artifact** (`artifactType: \"pm-review\"`, title: `PM Review for ticket <ticket-id>`)\n7. **Git diff artifact** (`artifactType: \"git-diff\"`, title: `Git diff for ticket <ticket-id>`)\n8. **Instructions Used artifact** (`artifactType: \"instructions-used\"`, title: `Instructions Used for ticket <ticket-id>`)\n\n**How to check for artifacts:**\n1. **First step (MANDATORY):** Call HAL API endpoint `/api/artifacts/get` with `{ ticketId: \"<ticket-id>\" }` to fetch all artifacts for the ticket.\n   - If `.hal/api-base-url` exists, read it and call: `POST ${baseUrl}/api/artifacts/get`\n   - If API call fails (404, 500, network error, etc.), **QA MUST FAIL** — you cannot verify artifacts exist, so assume they are missing.\n   - **DO NOT proceed with code review if artifact verification fails.**\n2. Filter the returned artifacts to find implementation artifacts (where `agent_type === \"implementation\"`).\n3. Check that all 8 required artifact types are present by matching artifact titles:\n   - `Plan for ticket <ticket-id>`\n   - `Worklog for ticket <ticket-id>`\n   - `Changed Files for ticket <ticket-id>`\n   - `Decisions for ticket <ticket-id>`\n   - `Verification for ticket <ticket-id>`\n   - `PM Review for ticket <ticket-id>`\n   - `Git diff for ticket <ticket-id>`\n   - `Instructions Used for ticket <ticket-id>`\n4. **CRITICAL: Validate Changed Files artifact content:**\n   - The Changed Files artifact must have NON-EMPTY `body_md` content (not just a title).\n   - If the Changed Files artifact exists but has empty or blank `body_md`, this is a PROCESS FAILURE and QA MUST FAIL immediately.\n   - The content must either:\n     - List file paths with descriptions (when files changed), OR\n     - Explicitly state \"No files changed.\" with a brief explanation (when no files changed).\n   - If Changed Files artifact is missing, blank, or contains only whitespace/placeholders, treat it as missing and fail QA.\n\n**Auto-fail when artifacts are missing or unverifiable:**\n- **If artifact API call fails (404, 500, network error, timeout):** QA **must fail immediately**. You cannot verify artifacts exist, so treat as missing.\n- **If any required artifact is missing:** QA **must fail immediately**.\n- **If Changed Files artifact is blank or empty:** QA **must fail immediately**. This is a PROCESS FAILURE. The Changed Files artifact must contain substantive content (either a list of changed files or an explicit \"No files changed.\" statement with explanation).\n- **Do NOT** attempt code review, verification, or any other QA work when artifacts cannot be verified or are missing.\n- **Do NOT** attempt to \"guess\" or recreate missing artifacts.\n- **Do NOT** proceed with code review and note \"artifacts couldn't be verified\" — this is a FAIL condition.\n- **Record a QA Fail outcome** by storing a QA report that clearly states the failure reason.\n- **The QA report must enumerate the specific missing artifacts** (or state \"Artifact verification failed: API returned [error]\" if API call failed). If Changed Files is blank/empty, explicitly state \"Changed Files artifact is blank or empty (process failure)\".\n- **Store the QA report in Supabase** using `insert_qa_artifact` tool (via HAL API or queue file).\n- **Move ticket to To-do** (`col-todo`) via HAL API.\n- **The final message must include:** `QA RESULT: FAIL — <ticket-id>` (see \"Completion message format requirement\" below).\n\n**Example QA report when artifacts are missing:**\n```markdown\n# QA Report for ticket 0076\n\n## Ticket & Deliverable\n[Brief summary from ticket]\n\n## Missing Required Implementation Artifacts\n\n**QA FAILED:** Required implementation artifacts are missing. QA cannot proceed without complete implementation artifacts.\n\n**Missing artifacts:**\n- Plan artifact (`Plan for ticket 0076`)\n- PM Review artifact (`PM Review for ticket 0076`)\n\n**Present artifacts:**\n- Worklog artifact\n- Changed Files artifact (present but blank/empty - process failure)\n- Decisions artifact\n- Verification artifact\n\n## Verdict\n\n**FAIL** — Implementation artifacts incomplete. Implementation agent must store all required artifacts before QA can proceed.\n\nQA RESULT: FAIL — 0076\n```\n\n**If all required artifacts are present:** Proceed with normal QA workflow (code review, verification, etc.).\n\n**CRITICAL:** Artifact verification is the **first and mandatory step** of QA. Do not skip it, do not defer it, do not proceed with code review if verification fails. If you cannot verify artifacts exist, the ticket fails QA.\n\n**Changed Files artifact validation:**\n- **MANDATORY:** The Changed Files artifact must be present and NON-EMPTY on every ticket.\n- **When files changed:** The artifact must contain a list of file paths and a brief one-line description of what changed in each file.\n- **When no files changed:** The artifact must explicitly state \"No files changed.\" followed by a short reason (e.g., \"Docs-only ticket handled via Supabase updates\", \"Investigation only\", \"Repro failed; no code changes made\").\n- **Process failure:** If the Changed Files artifact is blank, contains only headings, consists of placeholder text, or omits the explicit \"No files changed.\" statement when applicable, this is a PROCESS FAILURE and QA **MUST FAIL** immediately.\n- **QA must verify:** Check that the Changed Files artifact content is substantive and follows the requirements above. If it does not, fail QA and move the ticket back to To-do.\n\n## Required artifact (QA report)\n\n- **Storage:** Supabase `agent_artifacts` table (via HAL API endpoint `/api/artifacts/insert-qa`)\n- **When:** After performing QA (code review and, if possible, UI verification) for a ticket, OR when auto-failing due to missing implementation artifacts.\n- **Agent type:** `qa`\n- **Title format:** `QA report for ticket <ticket-id>`\n\n## QA report structure\n\n1. **Ticket & deliverable** — One-line goal, deliverable, and acceptance criteria from the ticket.\n2. **Missing Required Implementation Artifacts** (if applicable) — List of missing artifacts. If artifacts are missing, this section must be present and QA must fail.\n3. **Audit artifacts** — Confirm all required implementation artifacts are present in Supabase (plan, worklog, changed-files, decisions, verification, pm-review). Only include this section if all artifacts are present.\n   - **Changed Files artifact verification (MANDATORY):** Verify that the Changed Files artifact is non-empty and follows requirements:\n     - If files changed: Must list file paths with brief per-file descriptions (one line each)\n     - If no files changed: Must explicitly state \"No files changed.\" followed by a brief reason (e.g., \"Docs-only ticket handled via Supabase updates\", \"Investigation only\", \"Repro failed; no code changes made\")\n     - If Changed Files artifact is blank, empty, or omitted: QA **MUST FAIL** — this is a process failure\n4. **Code review** — PASS/FAIL with brief evidence (e.g. table of requirement vs implementation; file and line refs if helpful). Only include if artifacts are present.\n5. **Build verification** — **MANDATORY:** Run `npm run build:hal` (or `tsc -b`) and verify it completes with zero TypeScript errors. If TypeScript errors exist, QA **MUST FAIL** immediately. Document the build result (PASS/FAIL) and any TypeScript errors found. Only include if artifacts are present.\n6. **UI verification** — What was run: automated and/or manual steps. If automated UI was not run (e.g. native dialogs, login, or pickers), state that and list the manual steps the user should run. Only include if artifacts are present.\n7. **AC Confirmation Checklist** — **MANDATORY:** Enumerate every Acceptance Criteria from the ticket. For each AC, state \"Met\" or \"Not met\" with evidence (artifact links, file paths, screenshots, or reproduction steps). If any AC is not met, QA **MUST FAIL**. See `.cursor/rules/ac-confirmation-checklist.mdc` for full requirements. Only include if artifacts are present.\n8. **Verdict** — Implementation complete? OK to merge? Any blocking manual verification? Must clearly state PASS or FAIL.\n\n## Storing QA report\n\n**CRITICAL: You must make actual HTTP API calls, not just include JSON blocks in your message.**\n\n**How to store the QA report:**\n\n1. Read the API base URL from `.hal/api-base-url` (if it exists)\n2. Make an HTTP POST request to `${baseUrl}/api/artifacts/insert-qa` with:\n   - Headers: `Content-Type: application/json`\n   - Body: `{ \"ticketId\": \"0076\", \"title\": \"QA report for ticket 0076\", \"body_md\": \"<full markdown content>\" }`\n3. Use `curl` or `run_terminal_cmd` to execute the API call\n4. Verify the response indicates success\n\n**Example:**\n```bash\ncurl -X POST ${baseUrl}/api/artifacts/insert-qa \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"ticketId\":\"0076\",\"title\":\"QA report for ticket 0076\",\"body_md\":\"# QA Report\\n\\n...\"}'\n```\n\n**DO NOT** just include JSON blocks in your message text - you must actually execute the API calls using terminal commands or HTTP requests.\n\n## QA completion: do not hand off to the user\n\nWhen the verdict is **PASS (OK to merge)**, QA must **complete the full workflow** — do not stop at a summary or \"next steps for the user.\"\n\n## Completion message format requirement\n\n**MANDATORY:** The final completion message to the user **must** include the ticket ID and an explicit PASS/FAIL outcome token in a consistent, easy-to-spot format.\n\n- **Format:** `QA RESULT: <PASS|FAIL> — <ticket-id>`\n- **Examples:**\n  - `QA RESULT: PASS — 0056`\n  - `QA RESULT: FAIL — 0056`\n- **Placement:** This must appear in the final summary message that QA sends to the user after completing all workflow steps (merge, branch deletion, ticket updates, etc.).\n- **Why:** HAL needs to reliably parse QA outcomes from chat transcripts. The format must be human-verifiable (no external tooling required) and consistently structured for automated interpretation.\n- **Verification:** A human can read the QA chat transcript in the app and immediately see the ticket ID and outcome without parsing complex prose.\n\n**If you are verifying from the feature branch** (normal workflow):\n\n1. **Complete AC Confirmation Checklist** — **MANDATORY:** Before proceeding, complete the AC Confirmation Checklist. Enumerate every Acceptance Criteria from the ticket, state \"Met\" or \"Not met\" for each with evidence. If any AC is not met, QA **MUST FAIL** and you must not proceed to step 2. See `.cursor/rules/ac-confirmation-checklist.mdc` for full requirements.\n2. **Store QA report in Supabase** — Make an HTTP POST request to `${baseUrl}/api/artifacts/insert-qa`. The QA report must include the AC Confirmation Checklist:\n   ```bash\n   curl -X POST ${baseUrl}/api/artifacts/insert-qa \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"ticketId\":\"0076\",\"title\":\"QA report for ticket 0076\",\"body_md\":\"<markdown>\"}'\n   ```\n3. **Update ticket body** (optional) — If needed, make an HTTP POST request to `${baseUrl}/api/tickets/update`:\n   ```bash\n   curl -X POST ${baseUrl}/api/tickets/update \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"ticketId\":\"0076\",\"body_md\":\"<updated markdown>\"}'\n   ```\n4. **Move ticket to Human in the Loop** — Make an HTTP POST request to `${baseUrl}/api/tickets/move`:\n   ```bash\n   curl -X POST ${baseUrl}/api/tickets/move \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"ticketId\":\"0076\",\"columnId\":\"col-human-in-the-loop\"}'\n   ```\n5. **Merge to main** — checkout `main`, merge the feature branch, push `main`.\n6. **Delete the feature branch** — local and remote (see `delete-branch-after-merge.mdc`).\n7. **Then** give your summary to the user. **The final message must include the AC Confirmation Checklist and:** `QA RESULT: PASS — <ticket-id>` (see \"Completion message format requirement\" above).\n\n**If you are verifying from `main`** (implementation was merged to main for QA access):\n\n1. **Complete AC Confirmation Checklist** — **MANDATORY:** Before proceeding, complete the AC Confirmation Checklist. Enumerate every Acceptance Criteria from the ticket, state \"Met\" or \"Not met\" for each with evidence. If any AC is not met, QA **MUST FAIL** and you must not proceed to step 2. See `.cursor/rules/ac-confirmation-checklist.mdc` for full requirements.\n2. **Store QA report in Supabase** — Make an HTTP POST request to `${baseUrl}/api/artifacts/insert-qa`. The QA report must include the AC Confirmation Checklist. Include a note in the report that verification was performed against `main`.\n3. **Update ticket body** (optional) — If needed, make an HTTP POST request to `${baseUrl}/api/tickets/update` to note that verification was performed against `main`.\n4. **Move ticket to Human in the Loop** — Make an HTTP POST request to `${baseUrl}/api/tickets/move`.\n5. **Then** give your summary to the user. **The final message must include the AC Confirmation Checklist and:** `QA RESULT: PASS — <ticket-id>` (see \"Completion message format requirement\" above).\n\nDo not give a summary with \"next steps\" or \"run these commands\" — QA performs the merge (or confirms main) and branch deletion where applicable. The user receives the completed result.\n\n- Use a commit subject that includes the ticket ID (e.g. `qa(0033): add QA report, move to Human in the Loop`).\n- **If verdict is FAIL:** Do not merge. Store the QA report in Supabase, then **YOU MUST move the ticket to the top of To-do** (`col-todo` column) via HAL API. **This is MANDATORY** - failing to move the ticket to To-do means the QA workflow is incomplete. Summarize findings and recommend a bugfix ticket (see `bugfix-tracking.mdc`). **The final message must include:** `QA RESULT: FAIL — <ticket-id>` (see \"Completion message format requirement\" above).\n  \n  **FAIL workflow:**\n  1. **Complete AC Confirmation Checklist** — **MANDATORY:** Complete the AC Confirmation Checklist even when QA fails. Enumerate every Acceptance Criteria from the ticket, state \"Met\" or \"Not met\" for each with evidence. This helps identify which ACs were not met. See `.cursor/rules/ac-confirmation-checklist.mdc` for full requirements.\n  2. **Store QA report in Supabase** — Make an HTTP POST request to `${baseUrl}/api/artifacts/insert-qa`. The QA report must include the AC Confirmation Checklist showing which ACs were not met:\n     ```bash\n     curl -X POST ${baseUrl}/api/artifacts/insert-qa \\\n       -H \"Content-Type: application/json\" \\\n       -d '{\"ticketId\":\"0076\",\"title\":\"QA report for ticket 0076\",\"body_md\":\"<markdown>\"}'\n     ```\n  3. **Move ticket to To-do** — **REQUIRED**: You MUST make an HTTP POST request to `${baseUrl}/api/tickets/move`. The ticket MUST be moved to `col-todo` when QA fails. This is not optional:\n     ```bash\n     curl -X POST ${baseUrl}/api/tickets/move \\\n       -H \"Content-Type: application/json\" \\\n       -d '{\"ticketId\":\"0076\",\"columnId\":\"col-todo\"}'\n     ```\n     **Note:** The goal is to move failed tickets to the **top** of the To-do column for priority handling. The current move API (`/api/tickets/move`) appends tickets to the end of the column. If the API is enhanced in the future to support position parameters, use position 0 or a negative value to place at the top. For now, moving to `col-todo` satisfies the requirement even if it's at the end initially.\n  4. **Then** give your summary to the user. **The final message must include the AC Confirmation Checklist and:** `QA RESULT: FAIL — <ticket-id>`.\n\n## HAL API Calls\n\n**CRITICAL: You must make actual HTTP API calls using terminal commands (curl) or run_terminal_cmd tool, not just include JSON blocks in your message.**\n\nAll Supabase operations must be executed via HTTP POST requests to HAL API endpoints.\n\n**Available API endpoints:**\n\n- **`POST /api/artifacts/insert-qa`** — Store QA report in Supabase\n  - Body: `{ ticketId: string, title: string, body_md: string }`\n  - Example: `curl -X POST ${baseUrl}/api/artifacts/insert-qa -H \"Content-Type: application/json\" -d '{\"ticketId\":\"0076\",\"title\":\"QA report\",\"body_md\":\"...\"}'`\n\n- **`POST /api/tickets/update`** — Update ticket body in Supabase\n  - Body: `{ ticketId: string, body_md: string }`\n  - Example: `curl -X POST ${baseUrl}/api/tickets/update -H \"Content-Type: application/json\" -d '{\"ticketId\":\"0076\",\"body_md\":\"...\"}'`\n\n- **`POST /api/tickets/move`** — Move ticket to different column\n  - Body: `{ ticketId: string, columnId: string }`\n  - Example: `curl -X POST ${baseUrl}/api/tickets/move -H \"Content-Type: application/json\" -d '{\"ticketId\":\"0076\",\"columnId\":\"col-todo\"}'`\n\n- **`POST /api/tickets/get`** — Fetch ticket content\n  - Body: `{ ticketId: string }`\n  - Example: `curl -X POST ${baseUrl}/api/tickets/get -H \"Content-Type: application/json\" -d '{\"ticketId\":\"0076\"}'`\n\n**How to use:**\n1. Read the API base URL from `.hal/api-base-url` (if it exists)\n2. Use `run_terminal_cmd` tool with `curl` to make HTTP POST requests\n3. Verify the response indicates success before proceeding\n4. **DO NOT** just include JSON blocks in your message - you must actually execute the API calls\n\n**Important:** The instructions previously said to \"include JSON blocks in your message\" - this is incorrect. You must make actual HTTP API calls.\n\n## Scope\n\n- Applies to any QA or verification of a **ticketed** task (ticket in Supabase).\n- Keep the report concise; use bullets and tables where appropriate.\n- All artifacts are stored in Supabase, not in `docs/audit/` folders.",
      "agentTypes": [
        "all",
        "qa-agent",
        "implementation-agent"
      ],
      "topicId": "qa-audit-report",
      "isBasic": true,
      "isSituational": false
    },
    {
      "path": "state-management-change-documentation.mdc",
      "name": "state management change documentation",
      "description": "Require agents to document and justify any changes to application state management in review artifacts",
      "alwaysApply": true,
      "content": "# State Management Change Documentation\n\n**MANDATORY:** Any change to application state management (stores, reducers, context, persistence, query cache, etc.) must be **called out and justified** in the agent's review artifact(s), so reviewers can quickly understand behavioral risk.\n\n## What is a \"State Management Change\"?\n\nA **state management change** is any modification to how application state is stored, accessed, updated, or persisted. This includes:\n\n### Examples of State Management Changes\n\n- **Store modifications** (Zustand, Redux, Pinia, etc.)\n  - Adding/removing/modifying store slices or actions\n  - Changing store structure or initial state\n  - Modifying store selectors or computed values\n\n- **Context provider changes** (React Context, Vue provide/inject, etc.)\n  - Adding/removing/modifying context providers\n  - Changing context value structure\n  - Modifying context consumers\n\n- **Persistence/hydration changes**\n  - Adding/removing localStorage/sessionStorage usage\n  - Changing persistence keys or serialization format\n  - Modifying hydration logic (loading persisted state on app start)\n  - Changing persistence scope (what gets persisted vs. ephemeral)\n\n- **Query cache changes** (React Query, SWR, Apollo, etc.)\n  - Modifying cache keys or invalidation strategies\n  - Changing cache time-to-live (TTL) or stale-while-revalidate settings\n  - Adding/removing cache mutations or optimistic updates\n\n- **Cross-tab synchronization changes**\n  - Adding/removing `storage` event listeners\n  - Modifying broadcast channel or shared worker usage\n  - Changing how state syncs across browser tabs/windows\n\n- **State migration changes**\n  - Adding migration logic for existing persisted state\n  - Changing state schema versions\n  - Modifying backward compatibility handling\n\n## When This Requirement Applies\n\nThis requirement applies to **all agents** when making changes that affect state management:\n\n- **Implementation agents** — Must document state management changes in their **PM Review artifact**\n- **QA agents** — Must verify that state management changes are properly documented and check the impact during QA review\n- **Project Manager agents** — Must ensure state management changes are called out in PM reviews\n\n## Required Documentation: PM Review Checklist\n\n**MANDATORY:** When an implementation agent makes any state management change, they **must** include the following checklist in their **PM Review artifact** (stored in Supabase with `artifactType: \"pm-review\"`).\n\n### Copy/Paste Checklist Template\n\n```markdown\n## State Management Changes\n\n**State management changes made:** [Yes / No]\n\nIf Yes, complete the following:\n\n### What Changed\n- [ ] Store/Context/Cache modified: [specify which and what changed]\n- [ ] Persistence logic modified: [specify what changed]\n- [ ] Migration logic added: [specify what changed]\n- [ ] Other state management change: [specify what changed]\n\n### Why This Change Was Necessary\n[Brief explanation of why the state management change was required]\n\n### Migration Considerations\n- [ ] Existing persisted state affected: [Yes / No]\n- [ ] Backward compatibility: [Maintained / Broken / N/A]\n- [ ] Migration path: [Describe how existing users' state will be handled, if applicable]\n\n### User-Visible Impact\n- [ ] State persists across sessions: [Yes / No / Changed]\n- [ ] State syncs across tabs: [Yes / No / Changed]\n- [ ] User data loss risk: [None / Low / Medium / High]\n- [ ] Performance impact: [None / Low / Medium / High]\n- [ ] Breaking changes: [None / Describe if any]\n\n### Code Locations\n[Cite specific file paths and line numbers where state management changes were made, per `.cursor/rules/code-location-citations.mdc`]\n```\n\n## QA Review Requirements\n\n**MANDATORY:** When QA agents review a ticket that includes state management changes, they **must**:\n\n1. **Verify the PM Review artifact includes the state management checklist** — If state management changes were made but the checklist is missing or incomplete, QA **MUST FAIL** the ticket.\n\n2. **Review the documented impact** — QA should verify:\n   - The \"What Changed\" section accurately describes the code changes\n   - The \"Why This Change Was Necessary\" provides adequate justification\n   - Migration considerations are addressed if applicable\n   - User-visible impact is accurately assessed\n\n3. **Include state management review in QA report** — QA reports should include a section confirming:\n   - State management changes were properly documented (or \"No state management changes\" if none were made)\n   - The documented impact assessment appears reasonable\n   - Any concerns about user data loss, breaking changes, or migration issues\n\n### QA Report Template Addition\n\nQA reports should include:\n\n```markdown\n## State Management Review\n\n**State management changes:** [Yes / No]\n\nIf Yes:\n- [ ] PM Review includes complete state management checklist\n- [ ] Documented changes match code review findings\n- [ ] Migration considerations addressed: [Yes / No / N/A]\n- [ ] User-visible impact assessment appears reasonable: [Yes / No]\n- [ ] Concerns identified: [None / List any concerns]\n```\n\n## Integration with Existing Workflows\n\n### PM Review Artifact\n\nThe state management checklist must be included in the **PM Review artifact** stored in Supabase:\n- **Artifact type:** `pm-review`\n- **Title format:** `PM Review for ticket <ticket-id>`\n- **Storage:** Via HAL API endpoint `/api/artifacts/insert-pm-review` (or equivalent)\n\n### QA Audit Report\n\nQA agents must verify state management documentation as part of their standard QA workflow (see `.cursor/rules/qa-audit-report.mdc`).\n\n## Scope\n\n- Applies to **all agents** (implementation, QA, PM) when state management changes are involved\n- The checklist must be **human-verifiable** — a reviewer can open the PM Review artifact and immediately see whether state management changes were made and their impact\n- When in doubt, **document the change** — it's better to over-document than to miss a state management change that could affect user experience\n",
      "agentTypes": [
        "all",
        "qa-agent",
        "implementation-agent",
        "project-manager"
      ],
      "topicId": "state-management-change-documentation",
      "isBasic": true,
      "isSituational": false,
      "topicMetadata": {
        "title": "State Management Change Documentation",
        "description": "Require agents to document and justify any changes to application state management in review artifacts",
        "agentTypes": [
          "all"
        ]
      }
    }
  ],
  "situational": []
}