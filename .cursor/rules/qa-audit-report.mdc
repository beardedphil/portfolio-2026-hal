---
description: QA agents must store QA reports in Supabase via HAL API
alwaysApply: true
---

# QA Audit Report (QA Agents)

When you **QA a ticket** (e.g. user asks to "QA", "verify", or "check" a ticket that is allegedly complete), you **must** store a QA report in Supabase via HAL's API endpoints.

## Cloud QA workflow context

In cloud environments, QA agents may not have access to feature branches (only `main`). When this is the case, the implementation agent merges the feature branch to `main` before QA begins. QA must then verify from `main` rather than attempting to check out a feature branch. This workflow is indicated when the ticket states "merged to `main` for QA access" or similar language.

## Which branch to use (decision rule)

- **If the ticket or prompt states that the implementation was "merged to main for QA access"** (or that code is on `main` for QA): 
  - You **must** verify from the **`main`** branch. 
  - Do **not** attempt to locate, check out, or use the feature branch.
  - **Step 1:** Pull the latest `main` branch: `git checkout main && git pull origin main`
  - **Step 2:** Perform QA on `main` (code review and verification).
  - **Step 3:** Record in the QA report that verification was performed against `main` (e.g. "Verified on `main`; implementation was merged to main for QA access.").
  - **Step 4:** Store the QA report in Supabase via HAL API (see "Storing QA report" below).
  - **Step 5:** Move ticket to Human in the Loop via HAL API, then provide summary.
- **Otherwise:** use the feature branch named in the ticket's QA → Branch field (or the branch you were launched on). Perform QA on that branch, then follow the full workflow (merge to main, delete branch, etc.).

**Important:** When QA cannot access feature branches (cloud QA workflow), the implementation agent merges the feature branch to `main` before QA. In this case, QA must verify from `main` and record this in the QA report stored in Supabase.

## Required implementation artifacts (must be present before QA)

**MANDATORY:** Before performing any QA work, you **must** verify that all required implementation artifacts are present in Supabase. If any are missing, QA **must fail immediately** without attempting code review or verification.

**Required implementation artifacts:**
1. **Plan artifact** (`artifactType: "plan"`, title: `Plan for ticket <ticket-id>`)
2. **Worklog artifact** (`artifactType: "worklog"`, title: `Worklog for ticket <ticket-id>`)
3. **Changed Files artifact** (`artifactType: "changed-files"`, title: `Changed Files for ticket <ticket-id>`)
4. **Decisions artifact** (`artifactType: "decisions"`, title: `Decisions for ticket <ticket-id>`)
5. **Verification artifact** (`artifactType: "verification"`, title: `Verification for ticket <ticket-id>`)
6. **PM Review artifact** (`artifactType: "pm-review"`, title: `PM Review for ticket <ticket-id>`)
7. **Git diff artifact** (`artifactType: "git-diff"`, title: `Git diff for ticket <ticket-id>`)
8. **Instructions Used artifact** (`artifactType: "instructions-used"`, title: `Instructions Used for ticket <ticket-id>`)

**How to check for artifacts:**
1. **First step (MANDATORY):** Call HAL API endpoint `/api/artifacts/get` with `{ ticketId: "<ticket-id>" }` to fetch all artifacts for the ticket.
   - If `.hal/api-base-url` exists, read it and call: `POST ${baseUrl}/api/artifacts/get`
   - If API call fails (404, 500, network error, etc.), **QA MUST FAIL** — you cannot verify artifacts exist, so assume they are missing.
   - **DO NOT proceed with code review if artifact verification fails.**
2. Filter the returned artifacts to find implementation artifacts (where `agent_type === "implementation"`).
3. Check that all 8 required artifact types are present by matching artifact titles:
   - `Plan for ticket <ticket-id>`
   - `Worklog for ticket <ticket-id>`
   - `Changed Files for ticket <ticket-id>`
   - `Decisions for ticket <ticket-id>`
   - `Verification for ticket <ticket-id>`
 - `PM Review for ticket <ticket-id>`
 - `Git diff for ticket <ticket-id>`
 - `Instructions Used for ticket <ticket-id>`

**Auto-fail when artifacts are missing or unverifiable:**
- **If artifact API call fails (404, 500, network error, timeout):** QA **must fail immediately**. You cannot verify artifacts exist, so treat as missing.
- **If any required artifact is missing:** QA **must fail immediately**.
- **Do NOT** attempt code review, verification, or any other QA work when artifacts cannot be verified or are missing.
- **Do NOT** attempt to "guess" or recreate missing artifacts.
- **Do NOT** proceed with code review and note "artifacts couldn't be verified" — this is a FAIL condition.
- **Record a QA Fail outcome** by storing a QA report that clearly states the failure reason.
- **The QA report must enumerate the specific missing artifacts** (or state "Artifact verification failed: API returned [error]" if API call failed).
- **Store the QA report in Supabase** using `insert_qa_artifact` tool (via HAL API or queue file).
- **Move ticket to To-do** (`col-todo`) via HAL API.
- **The final message must include:** `QA RESULT: FAIL — <ticket-id>` (see "Completion message format requirement" below).

**Example QA report when artifacts are missing:**
```markdown
# QA Report for ticket 0076

## Ticket & Deliverable
[Brief summary from ticket]

## Missing Required Implementation Artifacts

**QA FAILED:** Required implementation artifacts are missing. QA cannot proceed without complete implementation artifacts.

**Missing artifacts:**
- Plan artifact (`Plan for ticket 0076`)
- PM Review artifact (`PM Review for ticket 0076`)

**Present artifacts:**
- Worklog artifact
- Changed Files artifact
- Decisions artifact
- Verification artifact

## Verdict

**FAIL** — Implementation artifacts incomplete. Implementation agent must store all required artifacts before QA can proceed.

QA RESULT: FAIL — 0076
```

**If all required artifacts are present:** Proceed with normal QA workflow (code review, verification, etc.).

**CRITICAL:** Artifact verification is the **first and mandatory step** of QA. Do not skip it, do not defer it, do not proceed with code review if verification fails. If you cannot verify artifacts exist, the ticket fails QA.

## UI Change Verification Checklist

**MANDATORY:** When a ticket involves UI changes (user interface, user experience, visual elements, layout, styling, components, forms, modals, dialogs, navigation, responsive design, accessibility features, or any visible changes to the application), QA **must** include the UI Change Verification Checklist in the QA report.

**When to use this checklist:**
- The ticket description mentions UI, UX, interface, visual, layout, styling, component, form, modal, dialog, navigation, responsive, accessibility, or similar terms
- The Changed Files artifact includes UI-related files (e.g., `.tsx`, `.jsx`, `.vue`, `.css`, `.scss`, component files, page files)
- The ticket's acceptance criteria reference user-visible changes or interactions
- The implementation involves any visible changes to the application

**How to use this checklist:**
1. **Copy the entire checklist below** into your QA report
2. **Mark each item** as **Pass**, **Fail**, or **N/A** (Not Applicable)
3. **For each Fail item**, provide:
   - Screenshot(s) showing the issue (if possible)
   - Steps to reproduce the failure
   - Description of what failed and why
4. **For each N/A item**, briefly explain why it doesn't apply to this ticket

**UI Change Verification Checklist:**

| Item | Status | Notes |
|------|--------|-------|
| **Happy Path** - Primary user flow works as expected | Pass / Fail / N/A | |
| **Edge Cases** - Handles empty/null/undefined data gracefully | Pass / Fail / N/A | |
| **Edge Cases** - Handles very long text/content without breaking layout | Pass / Fail / N/A | |
| **Edge Cases** - Handles rapid user interactions (e.g., rapid clicks) without errors | Pass / Fail / N/A | |
| **Accessibility** - Keyboard navigation works (Tab, Enter, Escape, Arrow keys as applicable) | Pass / Fail / N/A | |
| **Accessibility** - Focus indicators are visible and logical | Pass / Fail / N/A | |
| **Accessibility** - Screen reader announcements are appropriate (if applicable) | Pass / Fail / N/A | |
| **Responsive Layout** - Works correctly on mobile viewport (320px-768px width) | Pass / Fail / N/A | |
| **Responsive Layout** - Works correctly on tablet viewport (768px-1024px width) | Pass / Fail / N/A | |
| **Responsive Layout** - Works correctly on desktop viewport (1024px+ width) | Pass / Fail / N/A | |
| **Loading States** - Loading indicators appear and disappear appropriately (if applicable) | Pass / Fail / N/A | |
| **Empty States** - Empty state messages/placeholders display correctly (if applicable) | Pass / Fail / N/A | |
| **Error States** - Error messages display correctly and are user-friendly (if applicable) | Pass / Fail / N/A | |
| **Regression** - Existing functionality in the same area still works | Pass / Fail / N/A | |
| **Regression** - No visual regressions (layout, spacing, colors, fonts unchanged where not intended) | Pass / Fail / N/A | |
| **Regression** - No console errors introduced (check browser console) | Pass / Fail / N/A | |

**Documentation requirements for failures:**
- **Screenshots:** When an item fails, include screenshots showing the issue. If screenshots are not possible (e.g., in headless environment), describe the issue in detail.
- **Steps to reproduce:** For each failure, provide clear steps that a human can follow to reproduce the issue.
- **Failure description:** Explain what failed, why it failed, and what the expected behavior should be.

**Example checklist in QA report:**
```markdown
## UI Change Verification Checklist

| Item | Status | Notes |
|------|--------|-------|
| **Happy Path** - Primary user flow works as expected | ✅ Pass | User can complete the full workflow without errors |
| **Edge Cases** - Handles empty/null/undefined data gracefully | ✅ Pass | Empty state displays correctly |
| **Edge Cases** - Handles very long text/content without breaking layout | ⚠️ Fail | Long usernames overflow container. Screenshot: [link]. Steps: 1) Enter username with 200+ characters 2) Observe overflow |
| **Accessibility** - Keyboard navigation works | ✅ Pass | All interactive elements accessible via keyboard |
| **Responsive Layout** - Works correctly on mobile viewport | ✅ Pass | Layout adapts correctly at 375px width |
| **Loading States** - Loading indicators appear appropriately | ✅ Pass | Spinner shows during data fetch |
| **Regression** - Existing functionality still works | ✅ Pass | No breaking changes to related features |
```

**Important notes:**
- This checklist is designed for **UI-only verification** — you can complete it without inspecting code, by testing the application in a browser or UI testing environment.
- Two different QA agents should be able to run the same checks and get consistent results.
- If you cannot perform UI verification (e.g., no access to running application, headless environment without screenshots), mark items as **N/A** and explain why in the notes.
- This checklist **does not replace** code review or artifact verification — those remain mandatory.

## Acceptance criteria validation

**MANDATORY:** Every QA report **must** include an "Acceptance criteria validation" section that explicitly validates each acceptance criterion from the ticket.

**Required checklist item:**
- [ ] **I reviewed the ticket's Acceptance criteria and validated each item (or documented why an item could not be validated).**

**How to complete acceptance criteria validation:**

1. **Extract acceptance criteria from the ticket** — Copy each acceptance criterion exactly as it appears in the ticket (from the "Acceptance criteria" section).

2. **Enumerate each acceptance criterion** — For each acceptance criterion, create a line item in your QA report with:
   - The full text of the acceptance criterion (copy/paste from ticket)
   - A result status: **Pass**, **Fail**, or **Blocked**
   - Brief evidence or explanation

3. **Record results:**
   - **Pass** — The acceptance criterion is met. Provide brief evidence (e.g., "Verified in `src/App.tsx:42-67`", "Tested manually: user can complete workflow", "Build passes with zero errors").
   - **Fail** — The acceptance criterion is not met. Provide brief explanation of what failed and why.
   - **Blocked** — The acceptance criterion cannot be validated because:
     - The acceptance criterion is missing from the ticket
     - The acceptance criterion is ambiguous or unclear (explain what is missing or unclear)
     - Required information or context is missing to validate the criterion
     - **IMPORTANT:** When an acceptance criterion is missing or ambiguous, you **must** mark it as **Blocked** and explain what is missing. Do **not** silently pass QA or assume the criterion is met.

4. **Format for QA report:**
   ```markdown
   ## Acceptance criteria validation
   
   - [ ] **I reviewed the ticket's Acceptance criteria and validated each item (or documented why an item could not be validated).**
   
   ### Acceptance Criterion 1: [Copy/paste exact text from ticket]
   **Status:** Pass / Fail / Blocked
   **Evidence/Explanation:** [Brief evidence or explanation]
   
   ### Acceptance Criterion 2: [Copy/paste exact text from ticket]
   **Status:** Pass / Fail / Blocked
   **Evidence/Explanation:** [Brief evidence or explanation]
   
   [... continue for each acceptance criterion ...]
   ```

**Example acceptance criteria validation:**
```markdown
## Acceptance criteria validation

- [x] **I reviewed the ticket's Acceptance criteria and validated each item (or documented why an item could not be validated).**

### Acceptance Criterion 1: QA report template/rule contains a required section titled "Acceptance criteria validation".
**Status:** ✅ Pass
**Evidence/Explanation:** Verified in `.cursor/rules/qa-audit-report.mdc:XXX-YYY` — section "Acceptance criteria validation" is present and marked as MANDATORY.

### Acceptance Criterion 2: That section includes a checklist line: "[ ] I reviewed the ticket's Acceptance criteria and validated each item (or documented why an item could not be validated)."
**Status:** ✅ Pass
**Evidence/Explanation:** Verified in `.cursor/rules/qa-audit-report.mdc:XXX` — checklist line is present in the section.

### Acceptance Criterion 3: The QA report format requires QA to enumerate each acceptance criterion (copy/paste from ticket) and record a result (Pass/Fail/Blocked) with brief evidence.
**Status:** ✅ Pass
**Evidence/Explanation:** Verified in `.cursor/rules/qa-audit-report.mdc:XXX-YYY` — format section includes enumeration requirement with Pass/Fail/Blocked status options.

### Acceptance Criterion 4: A ticket with acceptance criteria missing/ambiguous causes QA to explicitly mark the item as Blocked and explain what is missing (without silently passing QA).
**Status:** ✅ Pass
**Evidence/Explanation:** Verified in `.cursor/rules/qa-audit-report.mdc:XXX` — instructions explicitly state that missing/ambiguous criteria must be marked as Blocked with explanation.

### Acceptance Criterion 5: Documentation/rules updated in a way that applies to future QA reports (not a one-off note in a single QA artifact).
**Status:** ✅ Pass
**Evidence/Explanation:** Verified — changes were made to `.cursor/rules/qa-audit-report.mdc` and Supabase instructions, which apply to all future QA reports.
```

**Example with Blocked criterion:**
```markdown
## Acceptance criteria validation

- [x] **I reviewed the ticket's Acceptance criteria and validated each item (or documented why an item could not be validated).**

### Acceptance Criterion 1: User can create a new ticket via the UI.
**Status:** ✅ Pass
**Evidence/Explanation:** Verified manually — user can click "Create ticket" button and form appears correctly.

### Acceptance Criterion 2: [Missing from ticket]
**Status:** ⚠️ Blocked
**Evidence/Explanation:** This acceptance criterion is missing from the ticket. The ticket only lists one acceptance criterion, but the goal mentions multiple requirements. Cannot validate without clear acceptance criteria.

### Acceptance Criterion 3: Tickets are saved to database.
**Status:** ⚠️ Blocked
**Evidence/Explanation:** Acceptance criterion is ambiguous — does not specify which database, what fields must be saved, or how to verify persistence. Need clarification on expected behavior and verification method.
```

**Important notes:**
- **Do NOT skip this section** — Every QA report must include acceptance criteria validation, even if the ticket has no acceptance criteria listed (in which case, mark as Blocked and explain).
- **Do NOT silently pass** — If acceptance criteria are missing or ambiguous, you **must** mark them as Blocked and explain what is missing. This prevents QA from passing tickets with unclear requirements.
- **Copy/paste exact text** — Use the exact wording from the ticket's "Acceptance criteria" section to avoid misinterpretation.
- **Be specific in evidence** — When marking Pass, provide concrete evidence (file paths, line numbers, test results, manual verification steps) that a human reviewer can verify.

## Required artifact (QA report)

- **Storage:** Supabase `agent_artifacts` table (via HAL API endpoint `/api/artifacts/insert-qa`)
- **When:** After performing QA (code review and, if possible, UI verification) for a ticket, OR when auto-failing due to missing implementation artifacts.
- **Agent type:** `qa`
- **Title format:** `QA report for ticket <ticket-id>`

## QA report structure

1. **Ticket & deliverable** — One-line goal, deliverable, and acceptance criteria from the ticket.
2. **Missing Required Implementation Artifacts** (if applicable) — List of missing artifacts. If artifacts are missing, this section must be present and QA must fail.
3. **Audit artifacts** — Confirm all required implementation artifacts are present in Supabase (plan, worklog, changed-files, decisions, verification, pm-review). Only include this section if all artifacts are present.
4. **Acceptance criteria validation** — **MANDATORY:** Enumerate each acceptance criterion from the ticket, copy/paste the exact text, and record Pass/Fail/Blocked status with brief evidence. If acceptance criteria are missing or ambiguous, mark as Blocked and explain what is missing. Only include if artifacts are present.
5. **Code review** — PASS/FAIL with brief evidence (e.g. table of requirement vs implementation; file and line refs if helpful). Only include if artifacts are present.
6. **Build verification** — **MANDATORY:** Run `npm run build:hal` (or `tsc -b`) and verify it completes with zero TypeScript errors. If TypeScript errors exist, QA **MUST FAIL** immediately. Document the build result (PASS/FAIL) and any TypeScript errors found. Only include if artifacts are present.
7. **UI Change Verification Checklist** — **MANDATORY when ticket involves UI changes:** If the ticket involves UI changes (see "UI Change Verification Checklist" section above for criteria), you **must** include the complete UI Change Verification Checklist in your QA report. Copy the checklist table, mark each item as Pass/Fail/N/A, and provide notes for failures. Only include if artifacts are present and ticket involves UI.
8. **UI verification** — What was run: automated and/or manual steps. If automated UI was not run (e.g. native dialogs, login, or pickers), state that and list the manual steps the user should run. Only include if artifacts are present.
9. **Verdict** — Implementation complete? OK to merge? Any blocking manual verification? Must clearly state PASS or FAIL.

## Storing QA report

**CRITICAL: You must make actual HTTP API calls, not just include JSON blocks in your message.**

**How to store the QA report:**

1. Read the API base URL from `.hal/api-base-url` (if it exists)
2. Make an HTTP POST request to `${baseUrl}/api/artifacts/insert-qa` with:
   - Headers: `Content-Type: application/json`
   - Body: `{ "ticketId": "0076", "title": "QA report for ticket 0076", "body_md": "<full markdown content>" }`
3. Use `curl` or `run_terminal_cmd` to execute the API call
4. Verify the response indicates success

**Example:**
```bash
curl -X POST ${baseUrl}/api/artifacts/insert-qa \
  -H "Content-Type: application/json" \
  -d '{"ticketId":"0076","title":"QA report for ticket 0076","body_md":"# QA Report\n\n..."}'
```

**DO NOT** just include JSON blocks in your message text - you must actually execute the API calls using terminal commands or HTTP requests.

## QA completion: do not hand off to the user

When the verdict is **PASS (OK to merge)**, QA must **complete the full workflow** — do not stop at a summary or "next steps for the user."

## Completion message format requirement

**MANDATORY:** The final completion message to the user **must** include the ticket ID and an explicit PASS/FAIL outcome token in a consistent, easy-to-spot format.

- **Format:** `QA RESULT: <PASS|FAIL> — <ticket-id>`
- **Examples:**
  - `QA RESULT: PASS — 0056`
  - `QA RESULT: FAIL — 0056`
- **Placement:** This must appear in the final summary message that QA sends to the user after completing all workflow steps (merge, branch deletion, ticket updates, etc.).
- **Why:** HAL needs to reliably parse QA outcomes from chat transcripts. The format must be human-verifiable (no external tooling required) and consistently structured for automated interpretation.
- **Verification:** A human can read the QA chat transcript in the app and immediately see the ticket ID and outcome without parsing complex prose.

**If you are verifying from the feature branch** (normal workflow):

1. **Store QA report in Supabase** — Make an HTTP POST request to `${baseUrl}/api/artifacts/insert-qa`:
   ```bash
   curl -X POST ${baseUrl}/api/artifacts/insert-qa \
     -H "Content-Type: application/json" \
     -d '{"ticketId":"0076","title":"QA report for ticket 0076","body_md":"<markdown>"}'
   ```
2. **Update ticket body** (optional) — If needed, make an HTTP POST request to `${baseUrl}/api/tickets/update`:
   ```bash
   curl -X POST ${baseUrl}/api/tickets/update \
     -H "Content-Type: application/json" \
     -d '{"ticketId":"0076","body_md":"<updated markdown>"}'
   ```
3. **Move ticket to Human in the Loop** — Make an HTTP POST request to `${baseUrl}/api/tickets/move`:
   ```bash
   curl -X POST ${baseUrl}/api/tickets/move \
     -H "Content-Type: application/json" \
     -d '{"ticketId":"0076","columnId":"col-human-in-the-loop"}'
   ```
4. **Merge to main** — checkout `main`, merge the feature branch, push `main`.
5. **Delete the feature branch** — local and remote (see `delete-branch-after-merge.mdc`).
6. **Then** give your summary to the user. **The final message must include:** `QA RESULT: PASS — <ticket-id>` (see "Completion message format requirement" above).

**If you are verifying from `main`** (implementation was merged to main for QA access):

1. **Store QA report in Supabase** — Make an HTTP POST request to `${baseUrl}/api/artifacts/insert-qa`. Include a note in the report that verification was performed against `main`.
2. **Update ticket body** (optional) — If needed, make an HTTP POST request to `${baseUrl}/api/tickets/update` to note that verification was performed against `main`.
3. **Move ticket to Human in the Loop** — Make an HTTP POST request to `${baseUrl}/api/tickets/move`.
4. **Then** give your summary to the user. **The final message must include:** `QA RESULT: PASS — <ticket-id>` (see "Completion message format requirement" above).

Do not give a summary with "next steps" or "run these commands" — QA performs the merge (or confirms main) and branch deletion where applicable. The user receives the completed result.

- Use a commit subject that includes the ticket ID (e.g. `qa(0033): add QA report, move to Human in the Loop`).
- **If verdict is FAIL:** Do not merge. Store the QA report in Supabase, then **YOU MUST move the ticket to the top of To-do** (`col-todo` column) via HAL API. **This is MANDATORY** - failing to move the ticket to To-do means the QA workflow is incomplete. Summarize findings and recommend a bugfix ticket (see `bugfix-tracking.mdc`). **The final message must include:** `QA RESULT: FAIL — <ticket-id>` (see "Completion message format requirement" above).
  
  **FAIL workflow:**
  1. **Store QA report in Supabase** — Make an HTTP POST request to `${baseUrl}/api/artifacts/insert-qa`:
     ```bash
     curl -X POST ${baseUrl}/api/artifacts/insert-qa \
       -H "Content-Type: application/json" \
       -d '{"ticketId":"0076","title":"QA report for ticket 0076","body_md":"<markdown>"}'
     ```
  2. **Move ticket to To-do** — **REQUIRED**: You MUST make an HTTP POST request to `${baseUrl}/api/tickets/move`. The ticket MUST be moved to `col-todo` when QA fails. This is not optional:
     ```bash
     curl -X POST ${baseUrl}/api/tickets/move \
       -H "Content-Type: application/json" \
       -d '{"ticketId":"0076","columnId":"col-todo"}'
     ```
     **Note:** The goal is to move failed tickets to the **top** of the To-do column for priority handling. The current move API (`/api/tickets/move`) appends tickets to the end of the column. If the API is enhanced in the future to support position parameters, use position 0 or a negative value to place at the top. For now, moving to `col-todo` satisfies the requirement even if it's at the end initially.
  3. **Then** give your summary to the user. **The final message must include:** `QA RESULT: FAIL — <ticket-id>`.

## HAL API Calls

**CRITICAL: You must make actual HTTP API calls using terminal commands (curl) or run_terminal_cmd tool, not just include JSON blocks in your message.**

All Supabase operations must be executed via HTTP POST requests to HAL API endpoints.

**Available API endpoints:**

- **`POST /api/artifacts/insert-qa`** — Store QA report in Supabase
  - Body: `{ ticketId: string, title: string, body_md: string }`
  - Example: `curl -X POST ${baseUrl}/api/artifacts/insert-qa -H "Content-Type: application/json" -d '{"ticketId":"0076","title":"QA report","body_md":"..."}'`

- **`POST /api/tickets/update`** — Update ticket body in Supabase
  - Body: `{ ticketId: string, body_md: string }`
  - Example: `curl -X POST ${baseUrl}/api/tickets/update -H "Content-Type: application/json" -d '{"ticketId":"0076","body_md":"..."}'`

- **`POST /api/tickets/move`** — Move ticket to different column
  - Body: `{ ticketId: string, columnId: string }`
  - Example: `curl -X POST ${baseUrl}/api/tickets/move -H "Content-Type: application/json" -d '{"ticketId":"0076","columnId":"col-todo"}'`

- **`POST /api/tickets/get`** — Fetch ticket content
  - Body: `{ ticketId: string }`
  - Example: `curl -X POST ${baseUrl}/api/tickets/get -H "Content-Type: application/json" -d '{"ticketId":"0076"}'`

**How to use:**
1. Read the API base URL from `.hal/api-base-url` (if it exists)
2. Use `run_terminal_cmd` tool with `curl` to make HTTP POST requests
3. Verify the response indicates success before proceeding
4. **DO NOT** just include JSON blocks in your message - you must actually execute the API calls

**Important:** The instructions previously said to "include JSON blocks in your message" - this is incorrect. You must make actual HTTP API calls.

## Scope

- Applies to any QA or verification of a **ticketed** task (ticket in Supabase).
- Keep the report concise; use bullets and tables where appropriate.
- All artifacts are stored in Supabase, not in `docs/audit/` folders.
