---
description: QA agents must store QA reports in Supabase via HAL API
alwaysApply: true
---

# QA Audit Report (QA Agents)

When you **QA a ticket** (verify, check a ticket that is allegedly complete), store a QA report via HAL API. See `docs/process/hal-tool-call-contract.mdc` for endpoints.

## Branch to use

- **If ticket states "merged to main for QA access":** Verify from `main`. Do not use feature branch. Record in report that verification was on `main`.
- **Otherwise:** Use feature branch from ticket; full workflow (merge to main, delete branch).

## 8 required implementation artifacts (must be present before QA)

1. plan, 2. worklog, 3. changed-files, 4. decisions, 5. verification, 6. pm-review, 7. git-diff, 8. instructions-used

**Changed Files:** Must be NON-EMPTY. When files changed: list paths with brief descriptions. When no files changed: state "No files changed." with reason. Blank/empty = PROCESS FAILURE.

**How to check:** `POST ${baseUrl}/api/artifacts/get` with `{ ticketId }`. Filter `agent_type === "implementation"`. Match titles `Plan for ticket X`, etc.

**Auto-fail:** API fails, any artifact missing, or Changed Files blank → QA FAIL immediately. Store QA report, move to `col-todo`, final message: `QA RESULT: FAIL — <ticket-id>`.

## QA report template

**MANDATORY:** QA agents **MUST** use the canonical QA report template when publishing QA artifacts via `/api/artifacts/insert-qa`.

**Template location:** `docs/templates/qa-report.template.md`

**Instructions:**
1. Copy the template from `docs/templates/qa-report.template.md`
2. Fill in all sections with actual content (remove all placeholder text)
3. Ensure all required headings are present:
   - **Verdict (PASS/FAIL)** — Required
   - **Acceptance Criteria verification** — Required (enumerate each AC, Met/Not met with evidence)
   - **Test matrix / scenarios executed** — Required
   - **Evidence (what was observed)** — Required
   - **Repro steps (for failures)** — Required for FAIL verdicts
   - **Environment** (app version/branch + browser) — Required
   - **Notes / Risks** — Required
4. The template supports both PASS and FAIL outcomes:
   - **PASS reports:** Must contain explicit "AC1/AC2/…" statements with evidence for each AC
   - **FAIL reports:** Must contain clear repro steps + expected vs actual + suspected area
5. Ensure the report contains substantive content (no placeholder-only sections) to pass artifact validation

**Example:** See `docs/templates/qa-report.example.md` for a filled example demonstrating correct usage.

## QA report structure

The template includes all required sections. When using the template, ensure you complete:

1. Ticket & deliverable
2. Missing artifacts (if any) — list them, then fail
3. Audit artifacts present (if all present)
   - **Changed Files artifact verification (MANDATORY):** Verify that the Changed Files artifact is non-empty and follows requirements:
     - If files changed: Must list file paths with brief per-file descriptions (one line each)
     - If no files changed: Must explicitly state "No files changed." followed by a brief reason (e.g., "Docs-only ticket handled via Supabase updates", "Investigation only", "Repro failed; no code changes made")
     - If Changed Files artifact is blank, empty, or omitted: QA **MUST FAIL** — this is a process failure
4. Code review — PASS/FAIL with evidence
5. Build verification — **MANDATORY:** `npm run build:hal`; TypeScript errors = FAIL
6. UI verification — automated and/or manual steps
7. AC Confirmation Checklist — enumerate each AC, Met/Not met with evidence; see `ac-confirmation-checklist.mdc`
8. Test Matrix / Scenarios Executed — List all test scenarios that were executed during QA with status
9. Evidence — What was observed during QA verification (code, artifacts, UI)
10. Repro Steps (For Failures Only) — Clear repro steps, expected vs actual, suspected area (FAIL reports only)
11. Environment — App version/branch + browser/runtime + OS
12. Notes / Risks — Additional notes, risks, blocking issues, recommendations
13. Verdict — PASS or FAIL

## Storing QA report

Make actual HTTP calls: `POST ${baseUrl}/api/artifacts/insert-qa` with `{ ticketId, title, body_md }`. Use `curl` or run_terminal_cmd. Do not just include JSON in your message.

## Implementation Agent Note (for FAIL verdicts)

**MANDATORY:** When a ticket fails QA (or HITL), you **MUST** create a separate, concise "Implementation agent note" artifact that explains why the ticket failed. This note is for implementation agents to quickly understand what needs to be fixed.

**Format:**
- Title: `Implementation agent note for ticket HAL-XXXX` (preferred) or `Note for implementation agent: HAL-XXXX`
- Keep it short (2-4 bullet points max)
- Focus on actionable items
- No detailed analysis—just what's wrong and what to fix
- Implementation agents are required to check for this artifact first before starting work

**Example structure:**
```markdown
# Implementation Agent Note: HAL-XXXX

## Status: FAIL

## Why This Ticket Failed

1. **Issue 1:** Brief description
2. **Issue 2:** Brief description

## Required Actions

1. Action item 1
2. Action item 2
3. Action item 3

## Code Review Notes

Brief note if implementation is otherwise correct.
```

**Store via:** `POST ${baseUrl}/api/artifacts/insert-qa` with `{ ticketId, title: "Implementation agent note for ticket HAL-XXXX", body_md }`

## Completion

- **PASS:** Store report, move to `col-human-in-the-loop`, merge to main, delete branch, then summary. Final message must include: `QA RESULT: PASS — <ticket-id>`
- **FAIL:** Store full QA report, **store Implementation agent note**, move to `col-todo`, then summary. Final message must include: `QA RESULT: FAIL — <ticket-id>`
